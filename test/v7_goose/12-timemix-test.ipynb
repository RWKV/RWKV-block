{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Usage:   \n",
      "  pip3 <command> [options]\n",
      "\n",
      "Commands:\n",
      "  install                     Install packages.\n",
      "  download                    Download packages.\n",
      "  uninstall                   Uninstall packages.\n",
      "  freeze                      Output installed packages in requirements format.\n",
      "  inspect                     Inspect the python environment.\n",
      "  list                        List installed packages.\n",
      "  show                        Show information about installed packages.\n",
      "  check                       Verify installed packages have compatible dependencies.\n",
      "  config                      Manage local and global configuration.\n",
      "  search                      Search PyPI for packages.\n",
      "  cache                       Inspect and manage pip's wheel cache.\n",
      "  index                       Inspect information available from package indexes.\n",
      "  wheel                       Build wheels from your requirements.\n",
      "  hash                        Compute hashes of package archives.\n",
      "  completion                  A helper command used for command completion.\n",
      "  debug                       Show information useful for debugging.\n",
      "  help                        Show help for commands.\n",
      "\n",
      "General Options:\n",
      "  -h, --help                  Show help.\n",
      "  --debug                     Let unhandled exceptions propagate outside the\n",
      "                              main subroutine, instead of logging them to\n",
      "                              stderr.\n",
      "  --isolated                  Run pip in an isolated mode, ignoring\n",
      "                              environment variables and user configuration.\n",
      "  --require-virtualenv        Allow pip to only run in a virtual environment;\n",
      "                              exit with an error otherwise.\n",
      "  --python <python>           Run pip with the specified Python interpreter.\n",
      "  -v, --verbose               Give more output. Option is additive, and can be\n",
      "                              used up to 3 times.\n",
      "  -V, --version               Show version and exit.\n",
      "  -q, --quiet                 Give less output. Option is additive, and can be\n",
      "                              used up to 3 times (corresponding to WARNING,\n",
      "                              ERROR, and CRITICAL logging levels).\n",
      "  --log <path>                Path to a verbose appending log.\n",
      "  --no-input                  Disable prompting for input.\n",
      "  --keyring-provider <keyring_provider>\n",
      "                              Enable the credential lookup via the keyring\n",
      "                              library if user input is allowed. Specify which\n",
      "                              mechanism to use [disabled, import, subprocess].\n",
      "                              (default: disabled)\n",
      "  --proxy <proxy>             Specify a proxy in the form\n",
      "                              scheme://[user:passwd@]proxy.server:port.\n",
      "  --retries <retries>         Maximum number of retries each connection should\n",
      "                              attempt (default 5 times).\n",
      "  --timeout <sec>             Set the socket timeout (default 15 seconds).\n",
      "  --exists-action <action>    Default action when a path already exists:\n",
      "                              (s)witch, (i)gnore, (w)ipe, (b)ackup, (a)bort.\n",
      "  --trusted-host <hostname>   Mark this host or host:port pair as trusted,\n",
      "                              even though it does not have valid or any HTTPS.\n",
      "  --cert <path>               Path to PEM-encoded CA certificate bundle. If\n",
      "                              provided, overrides the default. See 'SSL\n",
      "                              Certificate Verification' in pip documentation\n",
      "                              for more information.\n",
      "  --client-cert <path>        Path to SSL client certificate, a single file\n",
      "                              containing the private key and the certificate\n",
      "                              in PEM format.\n",
      "  --cache-dir <dir>           Store the cache data in <dir>.\n",
      "  --no-cache-dir              Disable the cache.\n",
      "  --disable-pip-version-check\n",
      "                              Don't periodically check PyPI to determine\n",
      "                              whether a new version of pip is available for\n",
      "                              download. Implied with --no-index.\n",
      "  --no-color                  Suppress colored output.\n",
      "  --no-python-version-warning\n",
      "                              Silence deprecation warnings for upcoming\n",
      "                              unsupported Pythons.\n",
      "  --use-feature <feature>     Enable new functionality, that may be backward\n",
      "                              incompatible.\n",
      "  --use-deprecated <feature>  Enable deprecated functionality, that will be\n",
      "                              removed in the future.\n"
     ]
    }
   ],
   "source": [
    "!pip3 install triton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'triton'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Import the block classes\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrwkv\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv7_goose\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mblock\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrwkv7_time_mix\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RWKV7TimeMix\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# File to load\u001b[39;00m\n\u001b[1;32m      9\u001b[0m MODEL_FILENAME\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv7-1B4.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/Recursal/rwkv-xp/trainer/RWKV_block/test/v7_goose/../../rwkv/v7_goose/block/rwkv7_time_mix.py:8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m functional \u001b[38;5;28;01mas\u001b[39;00m F\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrwkv7_block_config_map\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RWKV7BlockConfigMap\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkernel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrwkv7_attn_triton\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rwkv7_attn_triton\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mRWKV7TimeMix\u001b[39;00m(torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m     11\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03m    Time Mix block for RWKV V7\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Recursal/rwkv-xp/trainer/RWKV_block/test/v7_goose/../../rwkv/v7_goose/block/kernel/rwkv7_attn_triton.py:26\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# MIT License\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Copyright (c) 2024 Songlin Yang\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Copyright (c) 2024, Johan Sokrates Wind\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mth\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtriton\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtriton\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlanguage\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtl\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;129m@triton\u001b[39m\u001b[38;5;241m.\u001b[39mjit\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mIND4\u001b[39m(a,b,c,d,nb,nc,nd):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'triton'"
     ]
    }
   ],
   "source": [
    "# Configure the parent path to be the proj folder\n",
    "import sys, os, torch, time\n",
    "sys.path.append('../../')\n",
    "\n",
    "# Import the block classes\n",
    "from rwkv.v7_goose.block.rwkv7_time_mix import RWKV7TimeMix\n",
    "\n",
    "# File to load\n",
    "MODEL_FILENAME=\"v7-1B4.pth\"\n",
    "\n",
    "# Run device, and run dtype to use\n",
    "RUN_DEVICE=\"cpu\"\n",
    "RUN_DTYPE=torch.bfloat16\n",
    "\n",
    "# Check for cuda device\n",
    "if torch.cuda.is_available():\n",
    "    RUN_DEVICE=\"cuda:0\"\n",
    "\n",
    "# Check if the reference weights exists\n",
    "assert os.path.exists(f\"./.model/{MODEL_FILENAME}\"), \"The reference weights does not exist. Please download it first (00-model-download.ipynb)\"\n",
    "\n",
    "# Loads the model weights\n",
    "model_weight = torch.load(f\"./.model/{MODEL_FILENAME}\", map_location='cpu', weights_only=True, mmap=True)\n",
    "\n",
    "# Model filename\n",
    "print(f\"### Model filename: {MODEL_FILENAME}\")\n",
    "\n",
    "# Lets get the n_dim, and setup the test module\n",
    "n_dim = model_weight['emb.weight'].shape[1]\n",
    "print(f\"### Model n_dim: {n_dim}\")\n",
    "\n",
    "# List the model weights keys, and their shapes\n",
    "print(f\"### model weights keys:\")\n",
    "for key in model_weight:\n",
    "    print(f\"{key}: {model_weight[key].shape} - {model_weight[key].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### tmix named parameters:\n",
      "x_r: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "x_w: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "x_k: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "x_v: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "x_a: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "x_g: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "w1: torch.Size([2048, 96]) - torch.bfloat16\n",
      "w2: torch.Size([96, 2048]) - torch.bfloat16\n",
      "w0: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "a1: torch.Size([2048, 96]) - torch.bfloat16\n",
      "a2: torch.Size([96, 2048]) - torch.bfloat16\n",
      "a0: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "v1: torch.Size([2048, 64]) - torch.bfloat16\n",
      "v2: torch.Size([64, 2048]) - torch.bfloat16\n",
      "v0: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "g1: torch.Size([2048, 256]) - torch.bfloat16\n",
      "g2: torch.Size([256, 2048]) - torch.bfloat16\n",
      "k_k: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "k_a: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "r_k: torch.Size([32, 64]) - torch.bfloat16\n",
      "receptance.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "key.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "value.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "gate.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "output.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "ln_x.weight: torch.Size([2048]) - torch.bfloat16\n",
      "ln_x.bias: torch.Size([2048]) - torch.bfloat16\n",
      "### tmix state keys:\n",
      "tmix.x_r: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "tmix.x_w: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "tmix.x_k: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "tmix.x_v: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "tmix.x_a: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "tmix.x_g: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "tmix.w1: torch.Size([2048, 96]) - torch.bfloat16\n",
      "tmix.w2: torch.Size([96, 2048]) - torch.bfloat16\n",
      "tmix.w0: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "tmix.a1: torch.Size([2048, 96]) - torch.bfloat16\n",
      "tmix.a2: torch.Size([96, 2048]) - torch.bfloat16\n",
      "tmix.a0: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "tmix.v1: torch.Size([2048, 64]) - torch.bfloat16\n",
      "tmix.v2: torch.Size([64, 2048]) - torch.bfloat16\n",
      "tmix.v0: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "tmix.g1: torch.Size([2048, 256]) - torch.bfloat16\n",
      "tmix.g2: torch.Size([256, 2048]) - torch.bfloat16\n",
      "tmix.k_k: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "tmix.k_a: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "tmix.r_k: torch.Size([32, 64]) - torch.bfloat16\n",
      "tmix.receptance.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "tmix.key.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "tmix.value.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "tmix.gate.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "tmix.output.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "tmix.ln_x.weight: torch.Size([2048]) - torch.bfloat16\n",
      "tmix.ln_x.bias: torch.Size([2048]) - torch.bfloat16\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "# Initialize the channelmix state, and x state to test\n",
    "IN_TOKENS_LEN=8192\n",
    "x_state_0 = torch.ones(1, IN_TOKENS_LEN, n_dim, device=RUN_DEVICE, dtype=RUN_DTYPE)\n",
    "x_state_1 = torch.ones(1, IN_TOKENS_LEN, n_dim, device=RUN_DEVICE, dtype=RUN_DTYPE)\n",
    "x_state_2 = torch.ones(1, IN_TOKENS_LEN, n_dim, device=RUN_DEVICE, dtype=RUN_DTYPE)\n",
    "tmix_shift_0 = torch.ones(1, n_dim, device=RUN_DEVICE, dtype=RUN_DTYPE)\n",
    "tmix_shift_1 = torch.ones(1, n_dim, device=RUN_DEVICE, dtype=RUN_DTYPE)\n",
    "tmix_wkv_0 = torch.ones(1, n_dim // 64, 64, 64, device=RUN_DEVICE, dtype=RUN_DTYPE)\n",
    "tmix_wkv_1 = torch.ones(1, n_dim // 64, 64, 64, device=RUN_DEVICE, dtype=RUN_DTYPE)\n",
    "\n",
    "# Build the cmix block\n",
    "tmix = RWKV7TimeMix({ \"n_layer\":24, \"n_dim\":n_dim, \"layer_id\":0, \"device\":RUN_DEVICE, \"dtype\":RUN_DTYPE })\n",
    "tmix.load_from_model_state_dict(model_weight, 0)\n",
    "\n",
    "# Get the named parameters\n",
    "tmix_params = tmix.named_parameters()\n",
    "print(f\"### tmix named parameters:\")\n",
    "for name, param in tmix_params:\n",
    "    print(f\"{name}: {param.shape} - {param.dtype}\")\n",
    "\n",
    "# Log each item shape\n",
    "tmix_state = tmix.state_dict()\n",
    "print(f\"### tmix state keys:\")\n",
    "for key in tmix_state:\n",
    "    print(f\"tmix.{key}: {tmix_state[key].shape} - {tmix_state[key].dtype}\")\n",
    "print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 tmix forward passes (warmup): 16534.054040908813 ms (cpu, torch.bfloat16)\n",
      "1 tmix forward passes (normal): 16628.37781906128 ms (cpu, torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "# Iteration to test\n",
    "TEST_STEPS = 5\n",
    "\n",
    "### TMix\n",
    "with torch.inference_mode():\n",
    "\n",
    "    # This is a warmup\n",
    "    t0 = time.time()\n",
    "    out_x = x_state_0\n",
    "    t_shift = tmix_shift_0\n",
    "    t_wkv = tmix_wkv_0\n",
    "    v_first = x_state_2\n",
    "    for i in range(TEST_STEPS):\n",
    "        out_x, t_shift, t_wkv, v_first = tmix(x_state_1, t_shift, tmix_wkv_1, v_first)\n",
    "    t2 = time.time()\n",
    "    print(f'1 tmix forward passes (warmup): {(t2-t0)*1000/TEST_STEPS} ms ({RUN_DEVICE}, {RUN_DTYPE})')\n",
    "\n",
    "    # The actual run\n",
    "    t1 = time.time()\n",
    "    out_x = x_state_0\n",
    "    t_shift = tmix_shift_0\n",
    "    t_wkv = tmix_wkv_0\n",
    "    v_first = x_state_2\n",
    "    for i in range(TEST_STEPS):\n",
    "        out_x, t_shift, t_wkv, v_first = tmix(x_state_1, t_shift, tmix_wkv_1, v_first)\n",
    "    t2 = time.time()\n",
    "    print(f'1 tmix forward passes (normal): {(t2-t1)*1000/TEST_STEPS} ms ({RUN_DEVICE}, {RUN_DTYPE})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration to test\n",
    "TEST_STEPS = 5\n",
    "\n",
    "### TMix\n",
    "with torch.inference_mode():\n",
    "\n",
    "    # This is a warmup\n",
    "    t0 = time.time()\n",
    "    out_x = x_state_0\n",
    "    t_shift = tmix_shift_0\n",
    "    t_wkv = tmix_wkv_0\n",
    "    v_first = x_state_2\n",
    "    for i in range(TEST_STEPS):\n",
    "        out_x, t_shift, t_wkv, v_first = tmix.forward_with_default_compile(x_state_1, t_shift, tmix_wkv_1, v_first, out_x, t_shift, t_wkv, v_first)\n",
    "    t2 = time.time()\n",
    "    print(f'1 tmix forward passes (warmup): {(t2-t0)*1000/TEST_STEPS} ms ({RUN_DEVICE}, {RUN_DTYPE})')\n",
    "\n",
    "    # The actual run\n",
    "    t1 = time.time()\n",
    "    out_x = x_state_0\n",
    "    t_shift = tmix_shift_0\n",
    "    t_wkv = tmix_wkv_0\n",
    "    v_first = x_state_2\n",
    "    for i in range(TEST_STEPS):\n",
    "        out_x, t_shift, t_wkv, v_first = tmix.forward_with_default_compile(x_state_1, t_shift, tmix_wkv_1, v_first, out_x, t_shift, t_wkv, v_first)\n",
    "    t2 = time.time()\n",
    "    print(f'1 tmix forward passes (compiled): {(t2-t1)*1000/TEST_STEPS} ms ({RUN_DEVICE}, {RUN_DTYPE})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration to test\n",
    "TEST_STEPS = 5\n",
    "\n",
    "### TMix\n",
    "with torch.inference_mode():\n",
    "\n",
    "    # This is a warmup\n",
    "    t0 = time.time()\n",
    "    out_x = x_state_0\n",
    "    t_shift = tmix_shift_0\n",
    "    t_wkv = tmix_wkv_0\n",
    "    v_first = x_state_2\n",
    "    for i in range(TEST_STEPS):\n",
    "        out_x, t_shift, t_wkv, v_first = tmix.forward_with_reduce_compile(x_state_1, t_shift, tmix_wkv_1, v_first)\n",
    "    t2 = time.time()\n",
    "    print(f'1 tmix forward passes (warmup): {(t2-t0)*1000/TEST_STEPS} ms ({RUN_DEVICE}, {RUN_DTYPE})')\n",
    "\n",
    "    # The actual run\n",
    "    t1 = time.time()\n",
    "    out_x = x_state_0\n",
    "    t_shift = tmix_shift_0\n",
    "    t_wkv = tmix_wkv_0\n",
    "    v_first = x_state_2\n",
    "    for i in range(TEST_STEPS):\n",
    "        out_x, t_shift, t_wkv, v_first = tmix.forward_with_reduce_compile(x_state_1, t_shift, tmix_wkv_1, v_first)\n",
    "    t2 = time.time()\n",
    "    print(f'1 tmix forward passes (normal): {(t2-t1)*1000/TEST_STEPS} ms ({RUN_DEVICE}, {RUN_DTYPE})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export tmix1 state dict\n",
    "tmix_state = tmix.state_dict()\n",
    "\n",
    "# Log each item shape\n",
    "print(f\"### tmix state keys:\")\n",
    "for key in tmix_state:\n",
    "    print(f\"tmix.{key}: {tmix_state[key].shape} - {tmix_state[key].dtype}\")\n",
    "print(\"----\")\n",
    "\n",
    "# Build the tmix block\n",
    "tmix2 = RWKV7TimeMix({ \"n_layer\":24, \"n_dim\":n_dim, \"layer_id\":1, \"tmix_backend\":\"torch\", \"device\":RUN_DEVICE, \"dtype\":RUN_DTYPE })\n",
    "\n",
    "# Load the state dict\n",
    "tmix2.load_state_dict(tmix_state)\n",
    "\n",
    "# Log each item shape\n",
    "print(f\"### tmix2 state keys:\")\n",
    "for key in tmix_state:\n",
    "    print(f\"tmix.{key}: {tmix_state[key].shape} - {tmix_state[key].dtype}\")\n",
    "print(\"----\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
