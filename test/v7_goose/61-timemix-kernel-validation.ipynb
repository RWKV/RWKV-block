{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RWKV TMix block python / triton validation\n",
    "\n",
    "A much more aggressive, input / output delta comparision for timemix input / output between the various kernel implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Model filename: v7-1B4.pth\n",
      "### Model n_dim: 2048\n"
     ]
    }
   ],
   "source": [
    "# Configure the parent path to be the proj folder\n",
    "import sys, os, torch, time\n",
    "sys.path.append('../../')\n",
    "\n",
    "# Import the block classes\n",
    "from rwkv_block.v7_goose.block.rwkv7_time_mix import RWKV7TimeMix\n",
    "\n",
    "# File to load\n",
    "MODEL_FILENAME=\"v7-1B4.pth\"\n",
    "\n",
    "# Run device, and run dtype to use\n",
    "RUN_DEVICE=\"cpu\"\n",
    "RUN_DTYPE=torch.bfloat16\n",
    "\n",
    "# Check for cuda device\n",
    "if torch.cuda.is_available():\n",
    "    RUN_DEVICE=\"cuda:0\"\n",
    "\n",
    "# Check if the reference weights exists\n",
    "assert os.path.exists(f\"./.model/{MODEL_FILENAME}\"), \"The reference weights does not exist. Please download it first (00-model-download.ipynb)\"\n",
    "\n",
    "# Loads the model weights\n",
    "model_weight = torch.load(f\"./.model/{MODEL_FILENAME}\", map_location='cpu', weights_only=True, mmap=True)\n",
    "\n",
    "# Model filename\n",
    "print(f\"### Model filename: {MODEL_FILENAME}\")\n",
    "\n",
    "# Lets get the n_dim, and setup the test module\n",
    "n_dim = model_weight['emb.weight'].shape[1]\n",
    "print(f\"### Model n_dim: {n_dim}\")\n",
    "\n",
    "# # List the model weights keys, and their shapes\n",
    "# print(f\"### model weights keys:\")\n",
    "# for key in model_weight:\n",
    "#     print(f\"{key}: {model_weight[key].shape} - {model_weight[key].dtype}\")\n",
    "\n",
    "# Ensure cuda path is set, get the cuda nvcc path\n",
    "os.environ['CUDA_HOME'] = \"/usr/local/cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Testing the tmix blocks for 10 steps\n"
     ]
    }
   ],
   "source": [
    "# Initialize the channelmix state, and x state to test\n",
    "# NOTE: The triton kernel minimum chunk size is 16, it fallsback to pytorch mode otherwise\n",
    "# we intentionally DO not use a unit of 16, so the remainder pytorch code kicks in for triton\n",
    "IN_TOKENS_LEN=9000 \n",
    "x_state_0 = torch.ones(1, IN_TOKENS_LEN, n_dim, device=RUN_DEVICE, dtype=RUN_DTYPE)\n",
    "x_state_1 = torch.ones(1, IN_TOKENS_LEN, n_dim, device=RUN_DEVICE, dtype=RUN_DTYPE)\n",
    "x_state_2 = torch.ones(1, IN_TOKENS_LEN, n_dim, device=RUN_DEVICE, dtype=RUN_DTYPE)\n",
    "tmix_shift_0 = torch.ones(1, n_dim, device=RUN_DEVICE, dtype=RUN_DTYPE)\n",
    "tmix_shift_1 = torch.ones(1, n_dim, device=RUN_DEVICE, dtype=RUN_DTYPE)\n",
    "tmix_wkv_0 = torch.ones(1, n_dim // 64, 64, 64, device=RUN_DEVICE, dtype=torch.float)\n",
    "tmix_wkv_1 = torch.ones(1, n_dim // 64, 64, 64, device=RUN_DEVICE, dtype=torch.float)\n",
    "\n",
    "# Iteration to test\n",
    "TEST_STEPS = 10\n",
    "\n",
    "# Build the tmix blocks\n",
    "tmix_pytorch = RWKV7TimeMix({ \"n_layer\":24, \"n_dim\":n_dim, \"layer_id\":0, \"device\":RUN_DEVICE, \"dtype\":RUN_DTYPE, \"tmix_backend\":\"pytorch_ref\" })\n",
    "tmix_pytorch.load_from_model_state_dict(model_weight, 0)\n",
    "\n",
    "# Slower reference implementation\n",
    "tmix_pytorch_2 = RWKV7TimeMix({ \"n_layer\":24, \"n_dim\":n_dim, \"layer_id\":0, \"device\":RUN_DEVICE, \"dtype\":RUN_DTYPE, \"tmix_backend\":\"pytorch\" })\n",
    "tmix_pytorch_2.load_from_model_state_dict(model_weight, 0)\n",
    "\n",
    "tmix_triton = RWKV7TimeMix({ \"n_layer\":24, \"n_dim\":n_dim, \"layer_id\":0, \"device\":RUN_DEVICE, \"dtype\":RUN_DTYPE, \"tmix_backend\":\"triton\" })\n",
    "tmix_triton.load_from_model_state_dict(model_weight, 0)\n",
    "\n",
    "tmix_cuda = RWKV7TimeMix({ \"n_layer\":24, \"n_dim\":n_dim, \"layer_id\":0, \"device\":RUN_DEVICE, \"dtype\":RUN_DTYPE, \"tmix_backend\":\"cuda\" })\n",
    "tmix_cuda.load_from_model_state_dict(model_weight, 0)\n",
    "\n",
    "print(f\"### Testing the tmix blocks for {TEST_STEPS} steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### TMix\n",
    "# with torch.inference_mode():\n",
    "\n",
    "#     # This is a warmup\n",
    "#     t0 = time.time()\n",
    "#     out_x = x_state_0\n",
    "#     t_shift = tmix_shift_0\n",
    "#     t_wkv = tmix_wkv_0\n",
    "#     v_first = x_state_2\n",
    "#     for i in range(TEST_STEPS):\n",
    "#         out_x, t_shift, t_wkv, v_first = tmix_pytorch_2.forward_with_reduce_compile(x_state_1, t_shift, tmix_wkv_1, v_first)\n",
    "#     t2 = time.time()\n",
    "#     print(f'1 tmix_pytorch_2 reduce-compile forward passes (warmup): {(t2-t0)*1000/TEST_STEPS} ms ({RUN_DEVICE}, {RUN_DTYPE})')\n",
    "\n",
    "#     # The actual run\n",
    "#     t1 = time.time()\n",
    "#     out_x = x_state_0\n",
    "#     t_shift = tmix_shift_0\n",
    "#     t_wkv = tmix_wkv_0\n",
    "#     v_first = x_state_2\n",
    "#     for i in range(TEST_STEPS):\n",
    "#         out_x, t_shift, t_wkv, v_first = tmix_pytorch_2.forward_with_reduce_compile(x_state_1, t_shift, tmix_wkv_1, v_first)\n",
    "#     t2 = time.time()\n",
    "#     print(f'1 tmix_pytorch_2 reduce-compile forward passes (normal): {(t2-t1)*1000/TEST_STEPS} ms ({RUN_DEVICE}, {RUN_DTYPE})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 tmix_triton reduce-compile forward passes (warmup): 1003.6378145217896 ms (cuda:0, torch.bfloat16)\n",
      "1 tmix_triton reduce-compile forward passes (normal): 8.192968368530273 ms (cuda:0, torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "### TMix\n",
    "with torch.inference_mode():\n",
    "\n",
    "    # This is a warmup\n",
    "    t0 = time.time()\n",
    "    out_x = x_state_0\n",
    "    t_shift = tmix_shift_0\n",
    "    t_wkv = tmix_wkv_0\n",
    "    v_first = x_state_2\n",
    "    for i in range(TEST_STEPS):\n",
    "        out_x, t_shift, t_wkv, v_first = tmix_triton.forward_with_reduce_compile(x_state_1, t_shift, tmix_wkv_1, v_first)\n",
    "    t2 = time.time()\n",
    "    print(f'1 tmix_triton reduce-compile forward passes (warmup): {(t2-t0)*1000/TEST_STEPS} ms ({RUN_DEVICE}, {RUN_DTYPE})')\n",
    "\n",
    "    # The actual run\n",
    "    t1 = time.time()\n",
    "    out_x = x_state_0\n",
    "    t_shift = tmix_shift_0\n",
    "    t_wkv = tmix_wkv_0\n",
    "    v_first = x_state_2\n",
    "    for i in range(TEST_STEPS):\n",
    "        out_x, t_shift, t_wkv, v_first = tmix_triton.forward_with_reduce_compile(x_state_1, t_shift, tmix_wkv_1, v_first)\n",
    "    t2 = time.time()\n",
    "    print(f'1 tmix_triton reduce-compile forward passes (normal): {(t2-t1)*1000/TEST_STEPS} ms ({RUN_DEVICE}, {RUN_DTYPE})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TMix\n",
    "with torch.inference_mode():\n",
    "\n",
    "    # This is a warmup\n",
    "    t0 = time.time()\n",
    "    out_x = x_state_0\n",
    "    t_shift = tmix_shift_0\n",
    "    t_wkv = tmix_wkv_0\n",
    "    v_first = x_state_2\n",
    "    for i in range(TEST_STEPS):\n",
    "        out_x, t_shift, t_wkv, v_first = tmix_cuda.forward_with_reduce_compile(x_state_1, t_shift, tmix_wkv_1, v_first)\n",
    "    t2 = time.time()\n",
    "    print(f'1 tmix_cuda reduce-compile forward passes (warmup): {(t2-t0)*1000/TEST_STEPS} ms ({RUN_DEVICE}, {RUN_DTYPE})')\n",
    "\n",
    "    # The actual run\n",
    "    t1 = time.time()\n",
    "    out_x = x_state_0\n",
    "    t_shift = tmix_shift_0\n",
    "    t_wkv = tmix_wkv_0\n",
    "    v_first = x_state_2\n",
    "    for i in range(TEST_STEPS):\n",
    "        out_x, t_shift, t_wkv, v_first = tmix_cuda.forward_with_reduce_compile(x_state_1, t_shift, tmix_wkv_1, v_first)\n",
    "    t2 = time.time()\n",
    "    print(f'1 tmix_cuda reduce-compile forward passes (normal): {(t2-t1)*1000/TEST_STEPS} ms ({RUN_DEVICE}, {RUN_DTYPE})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TMix\n",
    "with torch.inference_mode():\n",
    "\n",
    "    # Get output with python\n",
    "    py_out_x, py_t_shift, py_t_wkv, py_v_first = tmix_pytorch.forward(\n",
    "        torch.ones(1, IN_TOKENS_LEN, n_dim, device=RUN_DEVICE, dtype=RUN_DTYPE),\n",
    "        torch.ones(1, n_dim, device=RUN_DEVICE, dtype=RUN_DTYPE), \n",
    "        torch.ones(1, n_dim // 64, 64, 64, device=RUN_DEVICE, dtype=torch.float), \n",
    "        torch.ones(1, IN_TOKENS_LEN, n_dim, device=RUN_DEVICE, dtype=RUN_DTYPE)\n",
    "    )\n",
    "\n",
    "    # Get output with python (again) : this catches initialisation issues\n",
    "    py2_out_x, py2_t_shift, py2_t_wkv, py2_v_first = tmix_pytorch_2.forward(\n",
    "        torch.ones(1, IN_TOKENS_LEN, n_dim, device=RUN_DEVICE, dtype=RUN_DTYPE),\n",
    "        torch.ones(1, n_dim, device=RUN_DEVICE, dtype=RUN_DTYPE), \n",
    "        torch.ones(1, n_dim // 64, 64, 64, device=RUN_DEVICE, dtype=torch.float), \n",
    "        torch.ones(1, IN_TOKENS_LEN, n_dim, device=RUN_DEVICE, dtype=RUN_DTYPE)\n",
    "    )\n",
    "\n",
    "    # Get output with triton\n",
    "    tr_out_x, tr_t_shift, tr_t_wkv, tr_v_first = tmix_triton.forward(\n",
    "        torch.ones(1, IN_TOKENS_LEN, n_dim, device=RUN_DEVICE, dtype=RUN_DTYPE),\n",
    "        torch.ones(1, n_dim, device=RUN_DEVICE, dtype=RUN_DTYPE), \n",
    "        torch.ones(1, n_dim // 64, 64, 64, device=RUN_DEVICE, dtype=torch.float), \n",
    "        torch.ones(1, IN_TOKENS_LEN, n_dim, device=RUN_DEVICE, dtype=RUN_DTYPE)\n",
    "    )\n",
    "\n",
    "    # Get the shape, and value range for each py_out_*\n",
    "    print(\"Forward py_out_x   (shape:\", py_out_x.shape, \"min:\", py_out_x.min().item(), \"max:\", py_out_x.max().item(), \")\")\n",
    "    print(\"Forward py_t_wkv   (shape:\", py_t_wkv.shape, \"min:\", py_t_wkv.min().item(), \"max:\", py_t_wkv.max().item(), \")\")\n",
    "    print(\"Forward py_t_shift (shape:\", py_t_shift.shape, \"min:\", py_t_shift.min().item(), \"max:\", py_t_shift.max().item(), \")\")\n",
    "    print(\"Forward py_v_first (shape:\", py_v_first.shape, \"min:\", py_v_first.min().item(), \"max:\", py_v_first.max().item(), \")\")\n",
    "\n",
    "    # Splitter\n",
    "    print(\"---\")\n",
    "\n",
    "    # Compute the delta between the two outputs (pytorch to pytorch)\n",
    "    py_py_out_x = py_out_x - py2_out_x\n",
    "    py_py_t_shift = py_t_shift - py2_t_shift\n",
    "    py_py_t_wkv = py_t_wkv - py2_t_wkv\n",
    "    py_py_v_first = py_v_first - py2_v_first\n",
    "\n",
    "    # Reshape for display\n",
    "    delta_py_py_out_x = py_py_out_x[-1][-1].view(n_dim // 64, -1).float().cpu().numpy()\n",
    "    delta_py_py_t_wkv = py_py_t_wkv.view(n_dim // 64 * 8, -1).float().cpu().numpy()\n",
    "    delta_py_py_t_shift = py_py_t_shift.view(n_dim // 64, -1).float().cpu().numpy()\n",
    "    delta_py_py_v_first = py_py_v_first[-1][-1].view(n_dim // 64, -1).float().cpu().numpy()\n",
    "\n",
    "    # Compute the max delta\n",
    "    abs_max_delta_py_py_out_x = max(delta_py_py_out_x.min().item(), delta_py_py_out_x.max().item())\n",
    "    abs_max_delta_py_py_t_wkv = max(delta_py_py_t_wkv.min().item(), delta_py_py_t_wkv.max().item())\n",
    "    abs_max_delta_py_py_t_shift = max(delta_py_py_t_shift.min().item(), delta_py_py_t_shift.max().item())\n",
    "    abs_max_delta_py_py_v_first = max(delta_py_py_v_first.min().item(), delta_py_py_v_first.max().item())\n",
    "\n",
    "    # Compute and print the max/min delta\n",
    "    print(\"Max delta (pytorch -> pytorch) for x       (shape:\", delta_py_py_out_x.shape,\" max:\", delta_py_py_out_x.max().item(),\", min:\", delta_py_py_out_x.min().item(),\")\")\n",
    "    print(\"Max delta (pytorch -> pytorch) for t_wkv   (shape:\", delta_py_py_t_wkv.shape,\" max:\", delta_py_py_t_wkv.max().item(),\", min:\", delta_py_py_t_wkv.min().item(),\")\")\n",
    "    print(\"Max delta (pytorch -> pytorch) for t_shift (shape:\", delta_py_py_t_shift.shape,\" max:\", delta_py_py_t_shift.max().item(),\", min:\", delta_py_py_t_shift.min().item(),\")\")\n",
    "    print(\"Max delta (pytorch -> pytorch) for v_first (shape:\", delta_py_py_v_first.shape,\" max:\", delta_py_py_v_first.max().item(),\", min:\", delta_py_py_v_first.min().item(),\")\")\n",
    "\n",
    "    # Splitter\n",
    "    print(\"---\")\n",
    "\n",
    "    # Compute the delta between the two outputs\n",
    "    py_tr_x = py_out_x - tr_out_x\n",
    "    py_tr_t_shift = py_t_shift - tr_t_shift\n",
    "    py_tr_t_wkv = py_t_wkv - tr_t_wkv\n",
    "    py_tr_v_first = py_v_first - tr_v_first\n",
    "\n",
    "    # Reshape for display\n",
    "    delta_tr_x = py_tr_x[-1][-1].view(n_dim // 64, -1).float().cpu().numpy()\n",
    "    delta_tr_t_wkv = py_tr_t_wkv.view(n_dim // 64 * 8, -1).float().cpu().numpy()\n",
    "    delta_tr_t_shift = py_tr_t_shift.view(n_dim // 64, -1).float().cpu().numpy()\n",
    "    delta_tr_v_first = py_tr_v_first[-1][-1].view(n_dim // 64, -1).float().cpu().numpy()\n",
    "\n",
    "    # Compute the max delta\n",
    "    abs_max_delta_tr_x = max(delta_tr_x.min().item(), delta_tr_x.max().item())\n",
    "    abs_max_delta_tr_t_wkv = max(delta_tr_t_wkv.min().item(), delta_tr_t_wkv.max().item())\n",
    "    abs_max_delta_tr_t_shift = max(delta_tr_t_shift.min().item(), delta_tr_t_shift.max().item())\n",
    "    abs_max_delta_tr_v_first = max(delta_tr_v_first.min().item(), delta_tr_v_first.max().item())\n",
    "\n",
    "    # Compute and print the max/min delta\n",
    "    print(\"Max delta (pytorch -> triton) for x       (shape:\", delta_tr_x.shape,\" max:\", delta_tr_x.max().item(),\", min:\", delta_tr_x.min().item(),\")\")\n",
    "    print(\"Max delta (pytorch -> triton) for t_wkv   (shape:\", delta_tr_t_wkv.shape,\" max:\", delta_tr_t_wkv.max().item(),\", min:\", delta_tr_t_wkv.min().item(),\")\")\n",
    "    print(\"Max delta (pytorch -> triton) for t_shift (shape:\", delta_tr_t_shift.shape,\" max:\", delta_tr_t_shift.max().item(),\", min:\", delta_tr_t_shift.min().item(),\")\")\n",
    "    print(\"Max delta (pytorch -> triton) for v_first (shape:\", delta_tr_v_first.shape,\" max:\", delta_tr_v_first.max().item(),\", min:\", delta_tr_v_first.min().item(),\")\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))  # Set a minimum figure size\n",
    "im = ax.imshow(delta_tr_x, cmap='seismic', aspect='auto')\n",
    "im.set_clim(-abs_max_delta_tr_x, abs_max_delta_tr_x)\n",
    "ax.set_title(\"Delta of last x output\")\n",
    "fig.colorbar(im)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))  # Set a minimum figure size\n",
    "im = ax.imshow(delta_tr_t_wkv, cmap='seismic', aspect='auto')\n",
    "im.set_clim(-abs_max_delta_tr_t_wkv, abs_max_delta_tr_t_wkv)\n",
    "ax.set_title(\"Delta of t_wkv output\")\n",
    "fig.colorbar(im)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))  # Set a minimum figure size\n",
    "im = ax.imshow(delta_tr_t_shift, cmap='seismic', aspect='auto')\n",
    "im.set_clim(-abs_max_delta_tr_t_shift, abs_max_delta_tr_t_shift)\n",
    "ax.set_title(\"Delta of t_shift output\")\n",
    "fig.colorbar(im)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))  # Set a minimum figure size\n",
    "im = ax.imshow(delta_tr_v_first, cmap='seismic', aspect='auto')\n",
    "im.set_clim(-abs_max_delta_tr_v_first, abs_max_delta_tr_v_first)\n",
    "ax.set_title(\"Delta of v_first output\")\n",
    "fig.colorbar(im)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## RWKV Block Python / Reference Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Reference RWKV TMix as per\n",
    "# # https://github.com/BlinkDL/ChatRWKV/blob/9284fa14d64146ee8817d134435102df9989c735/rwkv_pip_package/src/rwkv/model.py#L354C5-L378C48\n",
    "# def RWKV_x070_TMix_one(layer_id: int, H:int, N:int, x, x_prev, v_first, state, x_r, x_w, x_k, x_v, x_a, x_g, w0, w1, w2, a0, a1, a2, v0, v1, v2, g1, g2, k_k, k_a, r_k, R_, K_, V_, O_, ln_w, ln_b):\n",
    "#     xx = x_prev - x\n",
    "#     xr, xw, xk, xv, xa, xg = x+xx*x_r, x+xx*x_w, x+xx*x_k, x+xx*x_v, x+xx*x_a, x+xx*x_g\n",
    "\n",
    "#     r = xr @ R_\n",
    "#     w = torch.tanh(xw @ w1) @ w2\n",
    "#     k = xk @ K_\n",
    "#     v = xv @ V_\n",
    "#     a = torch.sigmoid(a0 + (xa @ a1) @ a2)\n",
    "#     g = torch.sigmoid(xg @ g1) @ g2\n",
    "\n",
    "#     kk = torch.nn.functional.normalize((k * k_k).view(H,N), dim=-1, p=2.0).view(H*N)\n",
    "#     k = k * (1 + (a-1) * k_a)\n",
    "#     if layer_id == 0: v_first = v\n",
    "#     else: v = v + (v_first - v) * torch.sigmoid(v0 + (xv @ v1) @ v2)\n",
    "#     w = torch.exp(-0.606531 * torch.sigmoid((w0 + w).float())) # 0.606531 = exp(-0.5)\n",
    "\n",
    "#     vk = v.view(H,N,1) @ k.view(H,1,N)\n",
    "#     ab = (-kk).view(H,N,1) @ (kk*a).view(H,1,N)\n",
    "#     state = state * w.view(H,1,N) + state @ ab.float() + vk.float()\n",
    "#     xx = (state.to(dtype=x.dtype) @ r.view(H,N,1))\n",
    "\n",
    "#     xx = torch.nn.functional.group_norm(xx.view(1,H*N), num_groups=H, weight=ln_w, bias=ln_b, eps = 64e-5).view(H*N)    \n",
    "#     xx = xx + ((r * k * r_k).view(H,N).sum(dim=-1, keepdim=True) * v.view(H,N)).view(H*N)\n",
    "#     return (xx * g) @ O_, x, state, v_first\n",
    "#     # return xx, t_shift, wkv_state, v_first\n",
    "\n",
    "# Reference RWKV TMix as per\n",
    "# https://github.com/BlinkDL/ChatRWKV/blob/9284fa14d64146ee8817d134435102df9989c735/rwkv_pip_package/src/rwkv/model.py#L407C9-L434C58\n",
    "def RWKV_x070_TMix_seq(layer_id: int, H:int, N:int, x, x_prev, v_first, state, x_r, x_w, x_k, x_v, x_a, x_g, w0, w1, w2, a0, a1, a2, v0, v1, v2, g1, g2, k_k, k_a, r_k, R_, K_, V_, O_, ln_w, ln_b):\n",
    "    T = x.shape[0]\n",
    "    xx = torch.cat((x_prev.unsqueeze(0), x[:-1,:])) - x\n",
    "    xr, xw, xk, xv, xa, xg = x+xx*x_r, x+xx*x_w, x+xx*x_k, x+xx*x_v, x+xx*x_a, x+xx*x_g\n",
    "\n",
    "    r = xr @ R_\n",
    "    w = torch.tanh(xw @ w1) @ w2\n",
    "    k = xk @ K_\n",
    "    v = xv @ V_\n",
    "    a = torch.sigmoid(a0 + (xa @ a1) @ a2)\n",
    "    g = torch.sigmoid(xg @ g1) @ g2\n",
    "\n",
    "    kk = torch.nn.functional.normalize((k * k_k).view(T,H,N), dim=-1, p=2.0).view(T,H*N)\n",
    "    k = k * (1 + (a-1) * k_a)\n",
    "    if layer_id == 0: v_first = v\n",
    "    else: v = v + (v_first - v) * torch.sigmoid(v0 + (xv @ v1) @ v2)\n",
    "\n",
    "    w = torch.exp(-0.606531 * torch.sigmoid((w0 + w).float())) # 0.606531 = exp(-0.5)\n",
    "    for t in range(T):\n",
    "        r_, w_, k_, v_, kk_, a_ = r[t], w[t], k[t], v[t], kk[t], a[t]\n",
    "        vk = v_.view(H,N,1) @ k_.view(H,1,N)\n",
    "        ab = (-kk_).view(H,N,1) @ (kk_*a_).view(H,1,N)\n",
    "        state = state * w_.view(H,1,N) + state @ ab.float() + vk.float()\n",
    "        xx[t] = (state.to(dtype=x.dtype) @ r_.view(H,N,1)).view(H*N)\n",
    "\n",
    "    xx = torch.nn.functional.group_norm(xx.view(T,H*N), num_groups=H, weight=ln_w, bias=ln_b, eps = 64e-5).view(T,H*N)\n",
    "    xx = xx + ((r * k * r_k).view(T,H,N).sum(dim=-1, keepdim=True) * v.view(T,H,N)).view(T,H*N)\n",
    "    return (xx * g) @ O_, x[-1,:], state, v_first\n",
    "\n",
    "# NOTE: We use tmix_pytorch, to get the weights\n",
    "def ref_tmix_forward(in_x, in_t_shift, in_t_wkv, in_v_first):\n",
    "    configMap = tmix_pytorch.configMap\n",
    "\n",
    "    layer_id = tmix_pytorch.layer_id\n",
    "    n_dim_att = configMap.get_n_dim_att()\n",
    "    head_size = configMap.head_size\n",
    "    n_head = n_dim_att // head_size\n",
    "\n",
    "    ############################\n",
    "    #\n",
    "    # IMPORTANT NOTE: For RWKV reference library, certain key operations are precomputed\n",
    "    # See from here: https://github.com/BlinkDL/ChatRWKV/blob/9284fa14d64146ee8817d134435102df9989c735/rwkv_pip_package/src/rwkv/model.py#L254\n",
    "    #\n",
    "    # - Transposing the key, value, receptance, output, and head values\n",
    "    #   ```\n",
    "    #   if 'key.weight' in k or 'value.weight' in k or 'receptance.weight' in k or 'output.weight' in k or 'head.weight' in k:\n",
    "    #       z[k] = z[k].t()\n",
    "    #   ```\n",
    "    # - Pre-Squeezing all weighted values\n",
    "    #   ```\n",
    "    #   z[k] = z[k].squeeze().to(dtype=DTYPE)\n",
    "    #   ```\n",
    "    # - Flatten the r_k value\n",
    "    #   ```\n",
    "    #   if k.endswith('att.r_k'): z[k] = z[k].flatten()\n",
    "    #   ```\n",
    "    # - Pre-Applying the block.0 ln0 to the embedding weights \n",
    "    #   (not applicable to the current test)\n",
    "    #   ```\n",
    "    #   z['emb.weight'] = F.layer_norm(z['emb.weight'], (args.n_embd,), weight=z['blocks.0.ln0.weight'], bias=z['blocks.0.ln0.bias'])\n",
    "    #   ```\n",
    "    #\n",
    "    ############################\n",
    "\n",
    "    # xx, state[i*3+0], state[i*3+1], v_first = RWKV_x070_TMix_one(i, self.n_head, self.head_size, xx, state[i*3+0], v_first, state[i*3+1],\n",
    "    #     z[att+'x_r'], z[att+'x_w'], z[att+'x_k'], z[att+'x_v'], z[att+'x_a'], z[att+'x_g'],\n",
    "    #     z[att+'w0'], z[att+'w1'], z[att+'w2'], z[att+'a0'], z[att+'a1'], z[att+'a2'], z[att+'v0'], z[att+'v1'], z[att+'v2'],\n",
    "    #     z[att+'g1'], z[att+'g2'], z[att+'k_k'], z[att+'k_a'], z[att+'r_k'],\n",
    "    #     z[att+'receptance.weight'], z[att+'key.weight'], z[att+'value.weight'], z[att+'output.weight'],\n",
    "    #     z[att+'ln_x.weight'], z[att+'ln_x.bias'])\n",
    "\n",
    "    assert layer_id == 0, \"Only layer_id 0 is supported for now, modify code below to inlcude v0,v1,v2 for other layers\"\n",
    "\n",
    "    out_x, out_t_shift, out_t_wkv, out_v_first = RWKV_x070_TMix_seq(\n",
    "        layer_id, n_head, head_size, \n",
    "        in_x, in_t_shift, in_v_first, in_t_wkv.float(),\n",
    "        tmix_pytorch.x_r.squeeze(), tmix_pytorch.x_w.squeeze(), tmix_pytorch.x_k.squeeze(), tmix_pytorch.x_v.squeeze(), tmix_pytorch.x_a.squeeze(), tmix_pytorch.x_g.squeeze(),\n",
    "        tmix_pytorch.w0.squeeze(), tmix_pytorch.w1.squeeze(), tmix_pytorch.w2.squeeze(), tmix_pytorch.a0.squeeze(), tmix_pytorch.a1.squeeze(), tmix_pytorch.a2.squeeze(), \n",
    "        None, None, None, # tmix_pytorch.v0.squeeze(), tmix_pytorch.v1.squeeze(), tmix_pytorch.v2.squeeze(),\n",
    "        tmix_pytorch.g1.squeeze(), tmix_pytorch.g2.squeeze(), tmix_pytorch.k_k.squeeze(), tmix_pytorch.k_a.squeeze(), tmix_pytorch.r_k.squeeze().flatten(),\n",
    "        tmix_pytorch.receptance.weight.t().squeeze(), tmix_pytorch.key.weight.t().squeeze(), tmix_pytorch.value.weight.t().squeeze(), tmix_pytorch.output.weight.t().squeeze(),\n",
    "        tmix_pytorch.ln_x.weight.squeeze(), tmix_pytorch.ln_x.bias.squeeze()\n",
    "    )\n",
    "    return out_x, out_t_shift, out_t_wkv.to(in_t_wkv.dtype), out_v_first\n",
    "\n",
    "with torch.inference_mode():\n",
    "    # Get output with python\n",
    "    ref_out_x, ref_t_shift, ref_t_wkv, ref_v_first = ref_tmix_forward(\n",
    "        torch.ones(IN_TOKENS_LEN, n_dim, device=RUN_DEVICE, dtype=RUN_DTYPE),\n",
    "        torch.ones(n_dim, device=RUN_DEVICE, dtype=RUN_DTYPE), \n",
    "        torch.ones(n_dim // 64, 64, 64, device=RUN_DEVICE, dtype=torch.float), \n",
    "        torch.ones(IN_TOKENS_LEN, n_dim, device=RUN_DEVICE, dtype=RUN_DTYPE)\n",
    "    )\n",
    "\n",
    "    delta_ref_py_out_x = (ref_out_x - py_out_x[0]).view(n_dim // 64, -1).float().cpu().numpy()\n",
    "    delta_ref_py_t_shift = (ref_t_shift - py_t_shift).view(n_dim // 64, -1).float().cpu().numpy()\n",
    "    delta_ref_py_t_wkv = (ref_t_wkv - py_t_wkv).view(n_dim // 64 * 8, -1).float().cpu().numpy()\n",
    "    delta_ref_py_v_first = (ref_v_first - py_v_first[0]).view(n_dim // 64, -1).float().cpu().numpy()\n",
    "\n",
    "    # Compute the max delta\n",
    "    abs_max_delta_ref_py_out_x = max(delta_ref_py_out_x.min().item(), delta_ref_py_out_x.max().item())\n",
    "    abs_max_delta_ref_py_t_shift = max(delta_ref_py_t_shift.min().item(), delta_ref_py_t_shift.max().item())\n",
    "    abs_max_delta_ref_py_t_wkv = max(delta_ref_py_t_wkv.min().item(), delta_ref_py_t_wkv.max().item())\n",
    "    abs_max_delta_ref_py_v_first = max(delta_ref_py_v_first.min().item(), delta_ref_py_v_first.max().item())\n",
    "\n",
    "    # Compute and print the max/min delta\n",
    "    print(\"Max delta (ref -> pytorch) for x       (shape:\", delta_ref_py_out_x.shape,\" max:\", delta_ref_py_out_x.max().item(),\", min:\", delta_ref_py_out_x.min().item(),\")\")\n",
    "    print(\"Max delta (ref -> pytorch) for t_shift (shape:\", delta_ref_py_t_shift.shape,\" max:\", delta_ref_py_t_shift.max().item(),\", min:\", delta_ref_py_t_shift.min().item(),\")\")\n",
    "    print(\"Max delta (ref -> pytorch) for t_wkv   (shape:\", delta_ref_py_t_wkv.shape,\" max:\", delta_ref_py_t_wkv.max().item(),\", min:\", delta_ref_py_t_wkv.min().item(),\")\")\n",
    "    print(\"Max delta (ref -> pytorch) for v_first (shape:\", delta_ref_py_v_first.shape,\" max:\", delta_ref_py_v_first.max().item(),\", min:\", delta_ref_py_v_first.min().item(),\")\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-3-12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
