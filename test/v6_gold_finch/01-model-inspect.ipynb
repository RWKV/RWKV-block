{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Model hidden_size: 2048\n",
      "### model weights keys:\n",
      "emb.weight: torch.Size([65536, 2048]) - torch.bfloat16\n",
      "blocks.0.ln1.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.0.ln1.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.0.ln2.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.0.ln2.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.0.ln0.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.0.ln0.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.0.att.time_maa_x: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.0.att.time_maa_w: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.0.att.time_maa_k: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.0.att.time_maa_v: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.0.att.time_maa_r: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.0.att.time_maa_g: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.0.att.time_maa_w1: torch.Size([2048, 160]) - torch.bfloat16\n",
      "blocks.0.att.time_maa_w2: torch.Size([5, 32, 2048]) - torch.bfloat16\n",
      "blocks.0.att.time_decay: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.0.att.time_decay_w1: torch.Size([2048, 64]) - torch.bfloat16\n",
      "blocks.0.att.time_decay_w2: torch.Size([64, 2048]) - torch.bfloat16\n",
      "blocks.0.att.time_faaaa: torch.Size([32, 64]) - torch.bfloat16\n",
      "blocks.0.att.receptance.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.0.att.key.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.0.att.value.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.0.att.gate.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.0.att.output.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.0.att.ln_x.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.0.att.ln_x.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.0.ffn.time_maa_k: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.0.ffn.time_maa_r: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.0.ffn.key.weight: torch.Size([7168, 2048]) - torch.bfloat16\n",
      "blocks.0.ffn.receptance.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.0.ffn.value.weight: torch.Size([2048, 7168]) - torch.bfloat16\n",
      "blocks.1.ln1.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.1.ln1.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.1.ln2.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.1.ln2.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.1.att.time_maa_x: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.1.att.time_maa_w: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.1.att.time_maa_k: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.1.att.time_maa_v: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.1.att.time_maa_r: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.1.att.time_maa_g: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.1.att.time_maa_w1: torch.Size([2048, 160]) - torch.bfloat16\n",
      "blocks.1.att.time_maa_w2: torch.Size([5, 32, 2048]) - torch.bfloat16\n",
      "blocks.1.att.time_decay: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.1.att.time_decay_w1: torch.Size([2048, 64]) - torch.bfloat16\n",
      "blocks.1.att.time_decay_w2: torch.Size([64, 2048]) - torch.bfloat16\n",
      "blocks.1.att.time_faaaa: torch.Size([32, 64]) - torch.bfloat16\n",
      "blocks.1.att.receptance.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.1.att.key.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.1.att.value.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.1.att.gate.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.1.att.output.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.1.att.ln_x.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.1.att.ln_x.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.1.ffn.time_maa_k: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.1.ffn.time_maa_r: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.1.ffn.key.weight: torch.Size([7168, 2048]) - torch.bfloat16\n",
      "blocks.1.ffn.receptance.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.1.ffn.value.weight: torch.Size([2048, 7168]) - torch.bfloat16\n",
      "blocks.2.ln1.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.2.ln1.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.2.ln2.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.2.ln2.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.2.att.time_maa_x: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.2.att.time_maa_w: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.2.att.time_maa_k: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.2.att.time_maa_v: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.2.att.time_maa_r: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.2.att.time_maa_g: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.2.att.time_maa_w1: torch.Size([2048, 160]) - torch.bfloat16\n",
      "blocks.2.att.time_maa_w2: torch.Size([5, 32, 2048]) - torch.bfloat16\n",
      "blocks.2.att.time_decay: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.2.att.time_decay_w1: torch.Size([2048, 64]) - torch.bfloat16\n",
      "blocks.2.att.time_decay_w2: torch.Size([64, 2048]) - torch.bfloat16\n",
      "blocks.2.att.time_faaaa: torch.Size([32, 64]) - torch.bfloat16\n",
      "blocks.2.att.receptance.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.2.att.key.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.2.att.value.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.2.att.gate.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.2.att.output.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.2.att.ln_x.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.2.att.ln_x.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.2.ffn.time_maa_k: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.2.ffn.time_maa_r: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.2.ffn.key.weight: torch.Size([7168, 2048]) - torch.bfloat16\n",
      "blocks.2.ffn.receptance.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.2.ffn.value.weight: torch.Size([2048, 7168]) - torch.bfloat16\n",
      "blocks.3.ln1.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.3.ln1.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.3.ln2.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.3.ln2.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.3.att.time_maa_x: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.3.att.time_maa_w: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.3.att.time_maa_k: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.3.att.time_maa_v: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.3.att.time_maa_r: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.3.att.time_maa_g: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.3.att.time_maa_w1: torch.Size([2048, 160]) - torch.bfloat16\n",
      "blocks.3.att.time_maa_w2: torch.Size([5, 32, 2048]) - torch.bfloat16\n",
      "blocks.3.att.time_decay: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.3.att.time_decay_w1: torch.Size([2048, 64]) - torch.bfloat16\n",
      "blocks.3.att.time_decay_w2: torch.Size([64, 2048]) - torch.bfloat16\n",
      "blocks.3.att.time_faaaa: torch.Size([32, 64]) - torch.bfloat16\n",
      "blocks.3.att.receptance.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.3.att.key.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.3.att.value.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.3.att.gate.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.3.att.output.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.3.att.ln_x.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.3.att.ln_x.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.3.ffn.time_maa_k: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.3.ffn.time_maa_r: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.3.ffn.key.weight: torch.Size([7168, 2048]) - torch.bfloat16\n",
      "blocks.3.ffn.receptance.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.3.ffn.value.weight: torch.Size([2048, 7168]) - torch.bfloat16\n",
      "blocks.4.ln1.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.4.ln1.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.4.ln2.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.4.ln2.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.4.att.time_maa_x: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.4.att.time_maa_w: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.4.att.time_maa_k: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.4.att.time_maa_v: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.4.att.time_maa_r: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.4.att.time_maa_g: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.4.att.time_maa_w1: torch.Size([2048, 160]) - torch.bfloat16\n",
      "blocks.4.att.time_maa_w2: torch.Size([5, 32, 2048]) - torch.bfloat16\n",
      "blocks.4.att.time_decay: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.4.att.time_decay_w1: torch.Size([2048, 64]) - torch.bfloat16\n",
      "blocks.4.att.time_decay_w2: torch.Size([64, 2048]) - torch.bfloat16\n",
      "blocks.4.att.time_faaaa: torch.Size([32, 64]) - torch.bfloat16\n",
      "blocks.4.att.receptance.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.4.att.key.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.4.att.value.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.4.att.gate.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.4.att.output.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.4.att.ln_x.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.4.att.ln_x.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.4.ffn.time_maa_k: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.4.ffn.time_maa_r: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.4.ffn.key.weight: torch.Size([7168, 2048]) - torch.bfloat16\n",
      "blocks.4.ffn.receptance.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.4.ffn.value.weight: torch.Size([2048, 7168]) - torch.bfloat16\n",
      "blocks.5.ln1.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.5.ln1.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.5.ln2.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.5.ln2.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.5.att.time_maa_x: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.5.att.time_maa_w: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.5.att.time_maa_k: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.5.att.time_maa_v: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.5.att.time_maa_r: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.5.att.time_maa_g: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.5.att.time_maa_w1: torch.Size([2048, 160]) - torch.bfloat16\n",
      "blocks.5.att.time_maa_w2: torch.Size([5, 32, 2048]) - torch.bfloat16\n",
      "blocks.5.att.time_decay: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.5.att.time_decay_w1: torch.Size([2048, 64]) - torch.bfloat16\n",
      "blocks.5.att.time_decay_w2: torch.Size([64, 2048]) - torch.bfloat16\n",
      "blocks.5.att.time_faaaa: torch.Size([32, 64]) - torch.bfloat16\n",
      "blocks.5.att.receptance.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.5.att.key.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.5.att.value.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.5.att.gate.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.5.att.output.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.5.att.ln_x.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.5.att.ln_x.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.5.ffn.time_maa_k: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.5.ffn.time_maa_r: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.5.ffn.key.weight: torch.Size([7168, 2048]) - torch.bfloat16\n",
      "blocks.5.ffn.receptance.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.5.ffn.value.weight: torch.Size([2048, 7168]) - torch.bfloat16\n",
      "blocks.6.ln1.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.6.ln1.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.6.ln2.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.6.ln2.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.6.att.time_maa_x: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.6.att.time_maa_w: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.6.att.time_maa_k: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.6.att.time_maa_v: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.6.att.time_maa_r: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.6.att.time_maa_g: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.6.att.time_maa_w1: torch.Size([2048, 160]) - torch.bfloat16\n",
      "blocks.6.att.time_maa_w2: torch.Size([5, 32, 2048]) - torch.bfloat16\n",
      "blocks.6.att.time_decay: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.6.att.time_decay_w1: torch.Size([2048, 64]) - torch.bfloat16\n",
      "blocks.6.att.time_decay_w2: torch.Size([64, 2048]) - torch.bfloat16\n",
      "blocks.6.att.time_faaaa: torch.Size([32, 64]) - torch.bfloat16\n",
      "blocks.6.att.receptance.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.6.att.key.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.6.att.value.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.6.att.gate.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.6.att.output.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.6.att.ln_x.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.6.att.ln_x.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.6.ffn.time_maa_k: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.6.ffn.time_maa_r: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.6.ffn.key.weight: torch.Size([7168, 2048]) - torch.bfloat16\n",
      "blocks.6.ffn.receptance.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.6.ffn.value.weight: torch.Size([2048, 7168]) - torch.bfloat16\n",
      "blocks.7.ln1.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.7.ln1.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.7.ln2.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.7.ln2.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.7.att.time_maa_x: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.7.att.time_maa_w: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.7.att.time_maa_k: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.7.att.time_maa_v: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.7.att.time_maa_r: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.7.att.time_maa_g: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.7.att.time_maa_w1: torch.Size([2048, 160]) - torch.bfloat16\n",
      "blocks.7.att.time_maa_w2: torch.Size([5, 32, 2048]) - torch.bfloat16\n",
      "blocks.7.att.time_decay: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.7.att.time_decay_w1: torch.Size([2048, 64]) - torch.bfloat16\n",
      "blocks.7.att.time_decay_w2: torch.Size([64, 2048]) - torch.bfloat16\n",
      "blocks.7.att.time_faaaa: torch.Size([32, 64]) - torch.bfloat16\n",
      "blocks.7.att.receptance.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.7.att.key.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.7.att.value.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.7.att.gate.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.7.att.output.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.7.att.ln_x.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.7.att.ln_x.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.7.ffn.time_maa_k: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.7.ffn.time_maa_r: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.7.ffn.key.weight: torch.Size([7168, 2048]) - torch.bfloat16\n",
      "blocks.7.ffn.receptance.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.7.ffn.value.weight: torch.Size([2048, 7168]) - torch.bfloat16\n",
      "blocks.8.ln1.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.8.ln1.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.8.ln2.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.8.ln2.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.8.att.time_maa_x: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.8.att.time_maa_w: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.8.att.time_maa_k: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.8.att.time_maa_v: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.8.att.time_maa_r: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.8.att.time_maa_g: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.8.att.time_maa_w1: torch.Size([2048, 160]) - torch.bfloat16\n",
      "blocks.8.att.time_maa_w2: torch.Size([5, 32, 2048]) - torch.bfloat16\n",
      "blocks.8.att.time_decay: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.8.att.time_decay_w1: torch.Size([2048, 64]) - torch.bfloat16\n",
      "blocks.8.att.time_decay_w2: torch.Size([64, 2048]) - torch.bfloat16\n",
      "blocks.8.att.time_faaaa: torch.Size([32, 64]) - torch.bfloat16\n",
      "blocks.8.att.receptance.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.8.att.key.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.8.att.value.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.8.att.gate.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.8.att.output.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.8.att.ln_x.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.8.att.ln_x.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.8.ffn.time_maa_k: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.8.ffn.time_maa_r: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.8.ffn.key.weight: torch.Size([7168, 2048]) - torch.bfloat16\n",
      "blocks.8.ffn.receptance.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.8.ffn.value.weight: torch.Size([2048, 7168]) - torch.bfloat16\n",
      "blocks.9.ln1.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.9.ln1.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.9.ln2.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.9.ln2.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.9.att.time_maa_x: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.9.att.time_maa_w: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.9.att.time_maa_k: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.9.att.time_maa_v: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.9.att.time_maa_r: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.9.att.time_maa_g: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.9.att.time_maa_w1: torch.Size([2048, 160]) - torch.bfloat16\n",
      "blocks.9.att.time_maa_w2: torch.Size([5, 32, 2048]) - torch.bfloat16\n",
      "blocks.9.att.time_decay: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.9.att.time_decay_w1: torch.Size([2048, 64]) - torch.bfloat16\n",
      "blocks.9.att.time_decay_w2: torch.Size([64, 2048]) - torch.bfloat16\n",
      "blocks.9.att.time_faaaa: torch.Size([32, 64]) - torch.bfloat16\n",
      "blocks.9.att.receptance.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.9.att.key.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.9.att.value.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.9.att.gate.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.9.att.output.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.9.att.ln_x.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.9.att.ln_x.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.9.ffn.time_maa_k: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.9.ffn.time_maa_r: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.9.ffn.key.weight: torch.Size([7168, 2048]) - torch.bfloat16\n",
      "blocks.9.ffn.receptance.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.9.ffn.value.weight: torch.Size([2048, 7168]) - torch.bfloat16\n",
      "blocks.10.ln1.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.10.ln1.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.10.ln2.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.10.ln2.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.10.att.time_maa_x: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.10.att.time_maa_w: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.10.att.time_maa_k: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.10.att.time_maa_v: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.10.att.time_maa_r: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.10.att.time_maa_g: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.10.att.time_maa_w1: torch.Size([2048, 160]) - torch.bfloat16\n",
      "blocks.10.att.time_maa_w2: torch.Size([5, 32, 2048]) - torch.bfloat16\n",
      "blocks.10.att.time_decay: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.10.att.time_decay_w1: torch.Size([2048, 64]) - torch.bfloat16\n",
      "blocks.10.att.time_decay_w2: torch.Size([64, 2048]) - torch.bfloat16\n",
      "blocks.10.att.time_faaaa: torch.Size([32, 64]) - torch.bfloat16\n",
      "blocks.10.att.receptance.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.10.att.key.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.10.att.value.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.10.att.gate.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.10.att.output.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.10.att.ln_x.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.10.att.ln_x.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.10.ffn.time_maa_k: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.10.ffn.time_maa_r: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.10.ffn.key.weight: torch.Size([7168, 2048]) - torch.bfloat16\n",
      "blocks.10.ffn.receptance.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.10.ffn.value.weight: torch.Size([2048, 7168]) - torch.bfloat16\n",
      "blocks.11.ln1.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.11.ln1.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.11.ln2.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.11.ln2.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.11.att.time_maa_x: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.11.att.time_maa_w: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.11.att.time_maa_k: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.11.att.time_maa_v: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.11.att.time_maa_r: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.11.att.time_maa_g: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.11.att.time_maa_w1: torch.Size([2048, 160]) - torch.bfloat16\n",
      "blocks.11.att.time_maa_w2: torch.Size([5, 32, 2048]) - torch.bfloat16\n",
      "blocks.11.att.time_decay: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.11.att.time_decay_w1: torch.Size([2048, 64]) - torch.bfloat16\n",
      "blocks.11.att.time_decay_w2: torch.Size([64, 2048]) - torch.bfloat16\n",
      "blocks.11.att.time_faaaa: torch.Size([32, 64]) - torch.bfloat16\n",
      "blocks.11.att.receptance.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.11.att.key.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.11.att.value.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.11.att.gate.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.11.att.output.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.11.att.ln_x.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.11.att.ln_x.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.11.ffn.time_maa_k: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.11.ffn.time_maa_r: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.11.ffn.key.weight: torch.Size([7168, 2048]) - torch.bfloat16\n",
      "blocks.11.ffn.receptance.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.11.ffn.value.weight: torch.Size([2048, 7168]) - torch.bfloat16\n",
      "blocks.12.ln1.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.12.ln1.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.12.ln2.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.12.ln2.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.12.att.time_maa_x: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.12.att.time_maa_w: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.12.att.time_maa_k: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.12.att.time_maa_v: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.12.att.time_maa_r: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.12.att.time_maa_g: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.12.att.time_maa_w1: torch.Size([2048, 160]) - torch.bfloat16\n",
      "blocks.12.att.time_maa_w2: torch.Size([5, 32, 2048]) - torch.bfloat16\n",
      "blocks.12.att.time_decay: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.12.att.time_decay_w1: torch.Size([2048, 64]) - torch.bfloat16\n",
      "blocks.12.att.time_decay_w2: torch.Size([64, 2048]) - torch.bfloat16\n",
      "blocks.12.att.time_faaaa: torch.Size([32, 64]) - torch.bfloat16\n",
      "blocks.12.att.receptance.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.12.att.key.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.12.att.value.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.12.att.gate.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.12.att.output.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.12.att.ln_x.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.12.att.ln_x.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.12.ffn.time_maa_k: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.12.ffn.time_maa_r: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.12.ffn.key.weight: torch.Size([7168, 2048]) - torch.bfloat16\n",
      "blocks.12.ffn.receptance.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.12.ffn.value.weight: torch.Size([2048, 7168]) - torch.bfloat16\n",
      "blocks.13.ln1.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.13.ln1.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.13.ln2.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.13.ln2.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.13.att.time_maa_x: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.13.att.time_maa_w: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.13.att.time_maa_k: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.13.att.time_maa_v: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.13.att.time_maa_r: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.13.att.time_maa_g: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.13.att.time_maa_w1: torch.Size([2048, 160]) - torch.bfloat16\n",
      "blocks.13.att.time_maa_w2: torch.Size([5, 32, 2048]) - torch.bfloat16\n",
      "blocks.13.att.time_decay: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.13.att.time_decay_w1: torch.Size([2048, 64]) - torch.bfloat16\n",
      "blocks.13.att.time_decay_w2: torch.Size([64, 2048]) - torch.bfloat16\n",
      "blocks.13.att.time_faaaa: torch.Size([32, 64]) - torch.bfloat16\n",
      "blocks.13.att.receptance.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.13.att.key.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.13.att.value.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.13.att.gate.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.13.att.output.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.13.att.ln_x.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.13.att.ln_x.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.13.ffn.time_maa_k: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.13.ffn.time_maa_r: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.13.ffn.key.weight: torch.Size([7168, 2048]) - torch.bfloat16\n",
      "blocks.13.ffn.receptance.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.13.ffn.value.weight: torch.Size([2048, 7168]) - torch.bfloat16\n",
      "blocks.14.ln1.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.14.ln1.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.14.ln2.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.14.ln2.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.14.att.time_maa_x: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.14.att.time_maa_w: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.14.att.time_maa_k: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.14.att.time_maa_v: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.14.att.time_maa_r: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.14.att.time_maa_g: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.14.att.time_maa_w1: torch.Size([2048, 160]) - torch.bfloat16\n",
      "blocks.14.att.time_maa_w2: torch.Size([5, 32, 2048]) - torch.bfloat16\n",
      "blocks.14.att.time_decay: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.14.att.time_decay_w1: torch.Size([2048, 64]) - torch.bfloat16\n",
      "blocks.14.att.time_decay_w2: torch.Size([64, 2048]) - torch.bfloat16\n",
      "blocks.14.att.time_faaaa: torch.Size([32, 64]) - torch.bfloat16\n",
      "blocks.14.att.receptance.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.14.att.key.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.14.att.value.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.14.att.gate.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.14.att.output.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.14.att.ln_x.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.14.att.ln_x.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.14.ffn.time_maa_k: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.14.ffn.time_maa_r: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.14.ffn.key.weight: torch.Size([7168, 2048]) - torch.bfloat16\n",
      "blocks.14.ffn.receptance.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.14.ffn.value.weight: torch.Size([2048, 7168]) - torch.bfloat16\n",
      "blocks.15.ln1.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.15.ln1.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.15.ln2.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.15.ln2.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.15.att.time_maa_x: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.15.att.time_maa_w: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.15.att.time_maa_k: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.15.att.time_maa_v: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.15.att.time_maa_r: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.15.att.time_maa_g: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.15.att.time_maa_w1: torch.Size([2048, 160]) - torch.bfloat16\n",
      "blocks.15.att.time_maa_w2: torch.Size([5, 32, 2048]) - torch.bfloat16\n",
      "blocks.15.att.time_decay: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.15.att.time_decay_w1: torch.Size([2048, 64]) - torch.bfloat16\n",
      "blocks.15.att.time_decay_w2: torch.Size([64, 2048]) - torch.bfloat16\n",
      "blocks.15.att.time_faaaa: torch.Size([32, 64]) - torch.bfloat16\n",
      "blocks.15.att.receptance.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.15.att.key.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.15.att.value.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.15.att.gate.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.15.att.output.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.15.att.ln_x.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.15.att.ln_x.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.15.ffn.time_maa_k: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.15.ffn.time_maa_r: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.15.ffn.key.weight: torch.Size([7168, 2048]) - torch.bfloat16\n",
      "blocks.15.ffn.receptance.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.15.ffn.value.weight: torch.Size([2048, 7168]) - torch.bfloat16\n",
      "blocks.16.ln1.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.16.ln1.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.16.ln2.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.16.ln2.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.16.att.time_maa_x: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.16.att.time_maa_w: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.16.att.time_maa_k: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.16.att.time_maa_v: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.16.att.time_maa_r: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.16.att.time_maa_g: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.16.att.time_maa_w1: torch.Size([2048, 160]) - torch.bfloat16\n",
      "blocks.16.att.time_maa_w2: torch.Size([5, 32, 2048]) - torch.bfloat16\n",
      "blocks.16.att.time_decay: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.16.att.time_decay_w1: torch.Size([2048, 64]) - torch.bfloat16\n",
      "blocks.16.att.time_decay_w2: torch.Size([64, 2048]) - torch.bfloat16\n",
      "blocks.16.att.time_faaaa: torch.Size([32, 64]) - torch.bfloat16\n",
      "blocks.16.att.receptance.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.16.att.key.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.16.att.value.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.16.att.gate.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.16.att.output.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.16.att.ln_x.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.16.att.ln_x.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.16.ffn.time_maa_k: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.16.ffn.time_maa_r: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.16.ffn.key.weight: torch.Size([7168, 2048]) - torch.bfloat16\n",
      "blocks.16.ffn.receptance.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.16.ffn.value.weight: torch.Size([2048, 7168]) - torch.bfloat16\n",
      "blocks.17.ln1.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.17.ln1.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.17.ln2.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.17.ln2.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.17.att.time_maa_x: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.17.att.time_maa_w: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.17.att.time_maa_k: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.17.att.time_maa_v: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.17.att.time_maa_r: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.17.att.time_maa_g: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.17.att.time_maa_w1: torch.Size([2048, 160]) - torch.bfloat16\n",
      "blocks.17.att.time_maa_w2: torch.Size([5, 32, 2048]) - torch.bfloat16\n",
      "blocks.17.att.time_decay: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.17.att.time_decay_w1: torch.Size([2048, 64]) - torch.bfloat16\n",
      "blocks.17.att.time_decay_w2: torch.Size([64, 2048]) - torch.bfloat16\n",
      "blocks.17.att.time_faaaa: torch.Size([32, 64]) - torch.bfloat16\n",
      "blocks.17.att.receptance.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.17.att.key.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.17.att.value.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.17.att.gate.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.17.att.output.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.17.att.ln_x.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.17.att.ln_x.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.17.ffn.time_maa_k: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.17.ffn.time_maa_r: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.17.ffn.key.weight: torch.Size([7168, 2048]) - torch.bfloat16\n",
      "blocks.17.ffn.receptance.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.17.ffn.value.weight: torch.Size([2048, 7168]) - torch.bfloat16\n",
      "blocks.18.ln1.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.18.ln1.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.18.ln2.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.18.ln2.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.18.att.time_maa_x: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.18.att.time_maa_w: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.18.att.time_maa_k: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.18.att.time_maa_v: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.18.att.time_maa_r: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.18.att.time_maa_g: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.18.att.time_maa_w1: torch.Size([2048, 160]) - torch.bfloat16\n",
      "blocks.18.att.time_maa_w2: torch.Size([5, 32, 2048]) - torch.bfloat16\n",
      "blocks.18.att.time_decay: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.18.att.time_decay_w1: torch.Size([2048, 64]) - torch.bfloat16\n",
      "blocks.18.att.time_decay_w2: torch.Size([64, 2048]) - torch.bfloat16\n",
      "blocks.18.att.time_faaaa: torch.Size([32, 64]) - torch.bfloat16\n",
      "blocks.18.att.receptance.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.18.att.key.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.18.att.value.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.18.att.gate.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.18.att.output.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.18.att.ln_x.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.18.att.ln_x.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.18.ffn.time_maa_k: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.18.ffn.time_maa_r: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.18.ffn.key.weight: torch.Size([7168, 2048]) - torch.bfloat16\n",
      "blocks.18.ffn.receptance.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.18.ffn.value.weight: torch.Size([2048, 7168]) - torch.bfloat16\n",
      "blocks.19.ln1.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.19.ln1.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.19.ln2.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.19.ln2.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.19.att.time_maa_x: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.19.att.time_maa_w: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.19.att.time_maa_k: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.19.att.time_maa_v: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.19.att.time_maa_r: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.19.att.time_maa_g: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.19.att.time_maa_w1: torch.Size([2048, 160]) - torch.bfloat16\n",
      "blocks.19.att.time_maa_w2: torch.Size([5, 32, 2048]) - torch.bfloat16\n",
      "blocks.19.att.time_decay: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.19.att.time_decay_w1: torch.Size([2048, 64]) - torch.bfloat16\n",
      "blocks.19.att.time_decay_w2: torch.Size([64, 2048]) - torch.bfloat16\n",
      "blocks.19.att.time_faaaa: torch.Size([32, 64]) - torch.bfloat16\n",
      "blocks.19.att.receptance.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.19.att.key.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.19.att.value.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.19.att.gate.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.19.att.output.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.19.att.ln_x.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.19.att.ln_x.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.19.ffn.time_maa_k: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.19.ffn.time_maa_r: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.19.ffn.key.weight: torch.Size([7168, 2048]) - torch.bfloat16\n",
      "blocks.19.ffn.receptance.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.19.ffn.value.weight: torch.Size([2048, 7168]) - torch.bfloat16\n",
      "blocks.20.ln1.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.20.ln1.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.20.ln2.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.20.ln2.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.20.att.time_maa_x: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.20.att.time_maa_w: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.20.att.time_maa_k: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.20.att.time_maa_v: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.20.att.time_maa_r: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.20.att.time_maa_g: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.20.att.time_maa_w1: torch.Size([2048, 160]) - torch.bfloat16\n",
      "blocks.20.att.time_maa_w2: torch.Size([5, 32, 2048]) - torch.bfloat16\n",
      "blocks.20.att.time_decay: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.20.att.time_decay_w1: torch.Size([2048, 64]) - torch.bfloat16\n",
      "blocks.20.att.time_decay_w2: torch.Size([64, 2048]) - torch.bfloat16\n",
      "blocks.20.att.time_faaaa: torch.Size([32, 64]) - torch.bfloat16\n",
      "blocks.20.att.receptance.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.20.att.key.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.20.att.value.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.20.att.gate.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.20.att.output.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.20.att.ln_x.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.20.att.ln_x.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.20.ffn.time_maa_k: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.20.ffn.time_maa_r: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.20.ffn.key.weight: torch.Size([7168, 2048]) - torch.bfloat16\n",
      "blocks.20.ffn.receptance.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.20.ffn.value.weight: torch.Size([2048, 7168]) - torch.bfloat16\n",
      "blocks.21.ln1.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.21.ln1.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.21.ln2.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.21.ln2.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.21.att.time_maa_x: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.21.att.time_maa_w: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.21.att.time_maa_k: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.21.att.time_maa_v: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.21.att.time_maa_r: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.21.att.time_maa_g: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.21.att.time_maa_w1: torch.Size([2048, 160]) - torch.bfloat16\n",
      "blocks.21.att.time_maa_w2: torch.Size([5, 32, 2048]) - torch.bfloat16\n",
      "blocks.21.att.time_decay: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.21.att.time_decay_w1: torch.Size([2048, 64]) - torch.bfloat16\n",
      "blocks.21.att.time_decay_w2: torch.Size([64, 2048]) - torch.bfloat16\n",
      "blocks.21.att.time_faaaa: torch.Size([32, 64]) - torch.bfloat16\n",
      "blocks.21.att.receptance.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.21.att.key.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.21.att.value.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.21.att.gate.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.21.att.output.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.21.att.ln_x.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.21.att.ln_x.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.21.ffn.time_maa_k: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.21.ffn.time_maa_r: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.21.ffn.key.weight: torch.Size([7168, 2048]) - torch.bfloat16\n",
      "blocks.21.ffn.receptance.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.21.ffn.value.weight: torch.Size([2048, 7168]) - torch.bfloat16\n",
      "blocks.22.ln1.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.22.ln1.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.22.ln2.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.22.ln2.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.22.att.time_maa_x: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.22.att.time_maa_w: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.22.att.time_maa_k: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.22.att.time_maa_v: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.22.att.time_maa_r: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.22.att.time_maa_g: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.22.att.time_maa_w1: torch.Size([2048, 160]) - torch.bfloat16\n",
      "blocks.22.att.time_maa_w2: torch.Size([5, 32, 2048]) - torch.bfloat16\n",
      "blocks.22.att.time_decay: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.22.att.time_decay_w1: torch.Size([2048, 64]) - torch.bfloat16\n",
      "blocks.22.att.time_decay_w2: torch.Size([64, 2048]) - torch.bfloat16\n",
      "blocks.22.att.time_faaaa: torch.Size([32, 64]) - torch.bfloat16\n",
      "blocks.22.att.receptance.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.22.att.key.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.22.att.value.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.22.att.gate.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.22.att.output.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.22.att.ln_x.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.22.att.ln_x.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.22.ffn.time_maa_k: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.22.ffn.time_maa_r: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.22.ffn.key.weight: torch.Size([7168, 2048]) - torch.bfloat16\n",
      "blocks.22.ffn.receptance.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.22.ffn.value.weight: torch.Size([2048, 7168]) - torch.bfloat16\n",
      "blocks.23.ln1.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.23.ln1.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.23.ln2.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.23.ln2.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.23.att.time_maa_x: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.23.att.time_maa_w: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.23.att.time_maa_k: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.23.att.time_maa_v: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.23.att.time_maa_r: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.23.att.time_maa_g: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.23.att.time_maa_w1: torch.Size([2048, 160]) - torch.bfloat16\n",
      "blocks.23.att.time_maa_w2: torch.Size([5, 32, 2048]) - torch.bfloat16\n",
      "blocks.23.att.time_decay: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.23.att.time_decay_w1: torch.Size([2048, 64]) - torch.bfloat16\n",
      "blocks.23.att.time_decay_w2: torch.Size([64, 2048]) - torch.bfloat16\n",
      "blocks.23.att.time_faaaa: torch.Size([32, 64]) - torch.bfloat16\n",
      "blocks.23.att.receptance.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.23.att.key.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.23.att.value.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.23.att.gate.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.23.att.output.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.23.att.ln_x.weight: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.23.att.ln_x.bias: torch.Size([2048]) - torch.bfloat16\n",
      "blocks.23.ffn.time_maa_k: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.23.ffn.time_maa_r: torch.Size([1, 1, 2048]) - torch.bfloat16\n",
      "blocks.23.ffn.key.weight: torch.Size([7168, 2048]) - torch.bfloat16\n",
      "blocks.23.ffn.receptance.weight: torch.Size([2048, 2048]) - torch.bfloat16\n",
      "blocks.23.ffn.value.weight: torch.Size([2048, 7168]) - torch.bfloat16\n",
      "ln_out.weight: torch.Size([2048]) - torch.bfloat16\n",
      "ln_out.bias: torch.Size([2048]) - torch.bfloat16\n",
      "head.weight: torch.Size([65536, 2048]) - torch.bfloat16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspecting the v6 x060 upgraded models\n",
    "import os, torch\n",
    "\n",
    "goldfinch_x060_upgraded = torch.load('./.model/L24-D2048-x060_goco-add-upgrade-chunk0-100m.pth')\n",
    "\n",
    "def log_model_weights(model_weight):\n",
    "    # Lets get the hidden_size, and setup the test module\n",
    "    hidden_size = model_weight['emb.weight'].shape[1]\n",
    "    print(f\"### Model hidden_size: {hidden_size}\")\n",
    "\n",
    "    # List the model weights keys, and their shapes\n",
    "    print(f\"### model weights keys:\")\n",
    "    for key in model_weight:\n",
    "        print(f\"{key}: {model_weight[key].shape} - {model_weight[key].dtype}\")\n",
    "\n",
    "    # Return hidden_size\n",
    "    return hidden_size\n",
    "\n",
    "log_model_weights(goldfinch_x060_upgraded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Model hidden_size: 768\n",
      "### model weights keys:\n",
      "time_maa_x: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "time_maa_token: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "time_maa_w1: torch.Size([768, 32]) - torch.bfloat16\n",
      "time_maa_w2: torch.Size([32, 768]) - torch.bfloat16\n",
      "emb.weight: torch.Size([65536, 768]) - torch.bfloat16\n",
      "blocks.0.ln1.weight: torch.Size([768]) - torch.bfloat16\n",
      "blocks.0.ln1.bias: torch.Size([768]) - torch.bfloat16\n",
      "blocks.0.ln2.weight: torch.Size([768]) - torch.bfloat16\n",
      "blocks.0.ln2.bias: torch.Size([768]) - torch.bfloat16\n",
      "blocks.0.ln0.weight: torch.Size([768]) - torch.bfloat16\n",
      "blocks.0.ln0.bias: torch.Size([768]) - torch.bfloat16\n",
      "blocks.0.att.time_maa_x: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.0.att.time_maa_r: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.0.att.time_maa_k: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.0.att.time_maa_v: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.0.att.time_maa_w: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.0.att.time_maa_v2: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.0.att.time_maa_w2: torch.Size([5, 32, 768]) - torch.bfloat16\n",
      "blocks.0.att.time_maa_w1: torch.Size([768, 160]) - torch.bfloat16\n",
      "blocks.0.att.time_decay: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.0.att.time_decay_w1: torch.Size([768, 64]) - torch.bfloat16\n",
      "blocks.0.att.time_decay_w2: torch.Size([64, 768]) - torch.bfloat16\n",
      "blocks.0.att.time_value2_w1: torch.Size([768, 64]) - torch.bfloat16\n",
      "blocks.0.att.time_value2_w2: torch.Size([64, 768]) - torch.bfloat16\n",
      "blocks.0.att.time_faaaa: torch.Size([12, 64]) - torch.bfloat16\n",
      "blocks.0.att.receptance.weight: torch.Size([768, 768]) - torch.bfloat16\n",
      "blocks.0.att.key.weight: torch.Size([768, 768]) - torch.bfloat16\n",
      "blocks.0.att.value.weight: torch.Size([768, 768]) - torch.bfloat16\n",
      "blocks.0.att.output.weight: torch.Size([768, 768]) - torch.bfloat16\n",
      "blocks.0.att.ln_x.weight: torch.Size([768]) - torch.bfloat16\n",
      "blocks.0.att.ln_x.bias: torch.Size([768]) - torch.bfloat16\n",
      "blocks.0.ffn.time_maa_k: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.0.ffn.time_maa_r: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.0.ffn.key.weight: torch.Size([2688, 768]) - torch.bfloat16\n",
      "blocks.0.ffn.receptance.weight: torch.Size([768, 768]) - torch.bfloat16\n",
      "blocks.0.ffn.value.weight: torch.Size([768, 2688]) - torch.bfloat16\n",
      "blocks.1.ln1.weight: torch.Size([768]) - torch.bfloat16\n",
      "blocks.1.ln1.bias: torch.Size([768]) - torch.bfloat16\n",
      "blocks.1.ln2.weight: torch.Size([768]) - torch.bfloat16\n",
      "blocks.1.ln2.bias: torch.Size([768]) - torch.bfloat16\n",
      "blocks.1.att.time_maa_x: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.1.att.time_maa_r: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.1.att.time_maa_k: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.1.att.time_maa_v: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.1.att.time_maa_w: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.1.att.time_maa_v2: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.1.att.time_maa_w2: torch.Size([5, 32, 768]) - torch.bfloat16\n",
      "blocks.1.att.time_maa_w1: torch.Size([768, 160]) - torch.bfloat16\n",
      "blocks.1.att.time_decay: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.1.att.time_decay_w1: torch.Size([768, 64]) - torch.bfloat16\n",
      "blocks.1.att.time_decay_w2: torch.Size([64, 768]) - torch.bfloat16\n",
      "blocks.1.att.time_value2_w1: torch.Size([768, 64]) - torch.bfloat16\n",
      "blocks.1.att.time_value2_w2: torch.Size([64, 768]) - torch.bfloat16\n",
      "blocks.1.att.time_faaaa: torch.Size([12, 64]) - torch.bfloat16\n",
      "blocks.1.att.receptance.weight: torch.Size([768, 768]) - torch.bfloat16\n",
      "blocks.1.att.key.weight: torch.Size([768, 768]) - torch.bfloat16\n",
      "blocks.1.att.value.weight: torch.Size([768, 768]) - torch.bfloat16\n",
      "blocks.1.att.output.weight: torch.Size([768, 768]) - torch.bfloat16\n",
      "blocks.1.att.ln_x.weight: torch.Size([768]) - torch.bfloat16\n",
      "blocks.1.att.ln_x.bias: torch.Size([768]) - torch.bfloat16\n",
      "blocks.1.ffn.time_maa_k: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.1.ffn.time_maa_r: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.1.ffn.key.weight: torch.Size([2688, 768]) - torch.bfloat16\n",
      "blocks.1.ffn.receptance.weight: torch.Size([768, 768]) - torch.bfloat16\n",
      "blocks.1.ffn.value.weight: torch.Size([768, 2688]) - torch.bfloat16\n",
      "blocks.2.ln1.weight: torch.Size([768]) - torch.bfloat16\n",
      "blocks.2.ln1.bias: torch.Size([768]) - torch.bfloat16\n",
      "blocks.2.ln2.weight: torch.Size([768]) - torch.bfloat16\n",
      "blocks.2.ln2.bias: torch.Size([768]) - torch.bfloat16\n",
      "blocks.2.att.time_maa_x: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.2.att.time_maa_r: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.2.att.time_maa_k: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.2.att.time_maa_v: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.2.att.time_maa_w: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.2.att.time_maa_v2: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.2.att.time_maa_w2: torch.Size([5, 32, 768]) - torch.bfloat16\n",
      "blocks.2.att.time_maa_w1: torch.Size([768, 160]) - torch.bfloat16\n",
      "blocks.2.att.time_decay: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.2.att.time_decay_w1: torch.Size([768, 64]) - torch.bfloat16\n",
      "blocks.2.att.time_decay_w2: torch.Size([64, 768]) - torch.bfloat16\n",
      "blocks.2.att.time_value2_w1: torch.Size([768, 64]) - torch.bfloat16\n",
      "blocks.2.att.time_value2_w2: torch.Size([64, 768]) - torch.bfloat16\n",
      "blocks.2.att.time_faaaa: torch.Size([12, 64]) - torch.bfloat16\n",
      "blocks.2.att.receptance.weight: torch.Size([768, 768]) - torch.bfloat16\n",
      "blocks.2.att.key.weight: torch.Size([768, 768]) - torch.bfloat16\n",
      "blocks.2.att.value.weight: torch.Size([768, 768]) - torch.bfloat16\n",
      "blocks.2.att.output.weight: torch.Size([768, 768]) - torch.bfloat16\n",
      "blocks.2.att.ln_x.weight: torch.Size([768]) - torch.bfloat16\n",
      "blocks.2.att.ln_x.bias: torch.Size([768]) - torch.bfloat16\n",
      "blocks.2.ffn.time_maa_k: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.2.ffn.time_maa_r: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.2.ffn.key.weight: torch.Size([2688, 768]) - torch.bfloat16\n",
      "blocks.2.ffn.receptance.weight: torch.Size([768, 768]) - torch.bfloat16\n",
      "blocks.2.ffn.value.weight: torch.Size([768, 2688]) - torch.bfloat16\n",
      "blocks.3.ln1.weight: torch.Size([768]) - torch.bfloat16\n",
      "blocks.3.ln1.bias: torch.Size([768]) - torch.bfloat16\n",
      "blocks.3.ln2.weight: torch.Size([768]) - torch.bfloat16\n",
      "blocks.3.ln2.bias: torch.Size([768]) - torch.bfloat16\n",
      "blocks.3.att.time_maa_x: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.3.att.time_maa_r: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.3.att.time_maa_k: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.3.att.time_maa_v: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.3.att.time_maa_w: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.3.att.time_maa_v2: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.3.att.time_maa_w2: torch.Size([5, 32, 768]) - torch.bfloat16\n",
      "blocks.3.att.time_maa_w1: torch.Size([768, 160]) - torch.bfloat16\n",
      "blocks.3.att.time_decay: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.3.att.time_decay_w1: torch.Size([768, 64]) - torch.bfloat16\n",
      "blocks.3.att.time_decay_w2: torch.Size([64, 768]) - torch.bfloat16\n",
      "blocks.3.att.time_value2_w1: torch.Size([768, 64]) - torch.bfloat16\n",
      "blocks.3.att.time_value2_w2: torch.Size([64, 768]) - torch.bfloat16\n",
      "blocks.3.att.time_faaaa: torch.Size([12, 64]) - torch.bfloat16\n",
      "blocks.3.att.receptance.weight: torch.Size([768, 768]) - torch.bfloat16\n",
      "blocks.3.att.key.weight: torch.Size([768, 768]) - torch.bfloat16\n",
      "blocks.3.att.value.weight: torch.Size([768, 768]) - torch.bfloat16\n",
      "blocks.3.att.output.weight: torch.Size([768, 768]) - torch.bfloat16\n",
      "blocks.3.att.ln_x.weight: torch.Size([768]) - torch.bfloat16\n",
      "blocks.3.att.ln_x.bias: torch.Size([768]) - torch.bfloat16\n",
      "blocks.3.ffn.time_maa_k: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.3.ffn.time_maa_r: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.3.ffn.key.weight: torch.Size([2688, 768]) - torch.bfloat16\n",
      "blocks.3.ffn.receptance.weight: torch.Size([768, 768]) - torch.bfloat16\n",
      "blocks.3.ffn.value.weight: torch.Size([768, 2688]) - torch.bfloat16\n",
      "blocks.4.ln1.weight: torch.Size([768]) - torch.bfloat16\n",
      "blocks.4.ln1.bias: torch.Size([768]) - torch.bfloat16\n",
      "blocks.4.ln2.weight: torch.Size([768]) - torch.bfloat16\n",
      "blocks.4.ln2.bias: torch.Size([768]) - torch.bfloat16\n",
      "blocks.4.att.time_maa_x: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.4.att.time_maa_r: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.4.att.time_maa_k: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.4.att.time_maa_v: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.4.att.time_maa_w: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.4.att.time_maa_v2: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.4.att.time_maa_w2: torch.Size([5, 32, 768]) - torch.bfloat16\n",
      "blocks.4.att.time_maa_w1: torch.Size([768, 160]) - torch.bfloat16\n",
      "blocks.4.att.time_decay: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.4.att.time_decay_w1: torch.Size([768, 64]) - torch.bfloat16\n",
      "blocks.4.att.time_decay_w2: torch.Size([64, 768]) - torch.bfloat16\n",
      "blocks.4.att.time_value2_w1: torch.Size([768, 64]) - torch.bfloat16\n",
      "blocks.4.att.time_value2_w2: torch.Size([64, 768]) - torch.bfloat16\n",
      "blocks.4.att.time_faaaa: torch.Size([12, 64]) - torch.bfloat16\n",
      "blocks.4.att.receptance.weight: torch.Size([768, 768]) - torch.bfloat16\n",
      "blocks.4.att.key.weight: torch.Size([768, 768]) - torch.bfloat16\n",
      "blocks.4.att.value.weight: torch.Size([768, 768]) - torch.bfloat16\n",
      "blocks.4.att.output.weight: torch.Size([768, 768]) - torch.bfloat16\n",
      "blocks.4.att.ln_x.weight: torch.Size([768]) - torch.bfloat16\n",
      "blocks.4.att.ln_x.bias: torch.Size([768]) - torch.bfloat16\n",
      "blocks.4.ffn.time_maa_k: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.4.ffn.time_maa_r: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.4.ffn.key.weight: torch.Size([2688, 768]) - torch.bfloat16\n",
      "blocks.4.ffn.receptance.weight: torch.Size([768, 768]) - torch.bfloat16\n",
      "blocks.4.ffn.value.weight: torch.Size([768, 2688]) - torch.bfloat16\n",
      "blocks.5.ln1.weight: torch.Size([768]) - torch.bfloat16\n",
      "blocks.5.ln1.bias: torch.Size([768]) - torch.bfloat16\n",
      "blocks.5.ln2.weight: torch.Size([768]) - torch.bfloat16\n",
      "blocks.5.ln2.bias: torch.Size([768]) - torch.bfloat16\n",
      "blocks.5.att.time_maa_x: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.5.att.time_maa_r: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.5.att.time_maa_k: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.5.att.time_maa_v: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.5.att.time_maa_w: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.5.att.time_maa_v2: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.5.att.time_maa_w2: torch.Size([5, 32, 768]) - torch.bfloat16\n",
      "blocks.5.att.time_maa_w1: torch.Size([768, 160]) - torch.bfloat16\n",
      "blocks.5.att.time_decay: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.5.att.time_decay_w1: torch.Size([768, 64]) - torch.bfloat16\n",
      "blocks.5.att.time_decay_w2: torch.Size([64, 768]) - torch.bfloat16\n",
      "blocks.5.att.time_value2_w1: torch.Size([768, 64]) - torch.bfloat16\n",
      "blocks.5.att.time_value2_w2: torch.Size([64, 768]) - torch.bfloat16\n",
      "blocks.5.att.time_faaaa: torch.Size([12, 64]) - torch.bfloat16\n",
      "blocks.5.att.receptance.weight: torch.Size([768, 768]) - torch.bfloat16\n",
      "blocks.5.att.key.weight: torch.Size([768, 768]) - torch.bfloat16\n",
      "blocks.5.att.value.weight: torch.Size([768, 768]) - torch.bfloat16\n",
      "blocks.5.att.output.weight: torch.Size([768, 768]) - torch.bfloat16\n",
      "blocks.5.att.ln_x.weight: torch.Size([768]) - torch.bfloat16\n",
      "blocks.5.att.ln_x.bias: torch.Size([768]) - torch.bfloat16\n",
      "blocks.5.ffn.time_maa_k: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.5.ffn.time_maa_r: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.5.ffn.key.weight: torch.Size([2688, 768]) - torch.bfloat16\n",
      "blocks.5.ffn.receptance.weight: torch.Size([768, 768]) - torch.bfloat16\n",
      "blocks.5.ffn.value.weight: torch.Size([768, 2688]) - torch.bfloat16\n",
      "blocks.6.ln1.weight: torch.Size([768]) - torch.bfloat16\n",
      "blocks.6.ln1.bias: torch.Size([768]) - torch.bfloat16\n",
      "blocks.6.ln2.weight: torch.Size([768]) - torch.bfloat16\n",
      "blocks.6.ln2.bias: torch.Size([768]) - torch.bfloat16\n",
      "blocks.6.att.time_maa_x: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.6.att.time_maa_r: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.6.att.time_maa_k: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.6.att.time_maa_v: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.6.att.time_maa_w: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.6.att.time_maa_v2: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.6.att.time_maa_w2: torch.Size([5, 32, 768]) - torch.bfloat16\n",
      "blocks.6.att.time_maa_w1: torch.Size([768, 160]) - torch.bfloat16\n",
      "blocks.6.att.time_decay: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.6.att.time_decay_w1: torch.Size([768, 64]) - torch.bfloat16\n",
      "blocks.6.att.time_decay_w2: torch.Size([64, 768]) - torch.bfloat16\n",
      "blocks.6.att.time_value2_w1: torch.Size([768, 64]) - torch.bfloat16\n",
      "blocks.6.att.time_value2_w2: torch.Size([64, 768]) - torch.bfloat16\n",
      "blocks.6.att.time_faaaa: torch.Size([12, 64]) - torch.bfloat16\n",
      "blocks.6.att.receptance.weight: torch.Size([768, 768]) - torch.bfloat16\n",
      "blocks.6.att.key.weight: torch.Size([768, 768]) - torch.bfloat16\n",
      "blocks.6.att.value.weight: torch.Size([768, 768]) - torch.bfloat16\n",
      "blocks.6.att.output.weight: torch.Size([768, 768]) - torch.bfloat16\n",
      "blocks.6.att.ln_x.weight: torch.Size([768]) - torch.bfloat16\n",
      "blocks.6.att.ln_x.bias: torch.Size([768]) - torch.bfloat16\n",
      "blocks.6.ffn.time_maa_k: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.6.ffn.time_maa_r: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.6.ffn.key.weight: torch.Size([2688, 768]) - torch.bfloat16\n",
      "blocks.6.ffn.receptance.weight: torch.Size([768, 768]) - torch.bfloat16\n",
      "blocks.6.ffn.value.weight: torch.Size([768, 2688]) - torch.bfloat16\n",
      "blocks.7.ln1.weight: torch.Size([768]) - torch.bfloat16\n",
      "blocks.7.ln1.bias: torch.Size([768]) - torch.bfloat16\n",
      "blocks.7.ln2.weight: torch.Size([768]) - torch.bfloat16\n",
      "blocks.7.ln2.bias: torch.Size([768]) - torch.bfloat16\n",
      "blocks.7.att.time_maa_x: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.7.att.time_maa_r: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.7.att.time_maa_k: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.7.att.time_maa_v: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.7.att.time_maa_w: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.7.att.time_maa_v2: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.7.att.time_maa_w2: torch.Size([5, 32, 768]) - torch.bfloat16\n",
      "blocks.7.att.time_maa_w1: torch.Size([768, 160]) - torch.bfloat16\n",
      "blocks.7.att.time_decay: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.7.att.time_decay_w1: torch.Size([768, 64]) - torch.bfloat16\n",
      "blocks.7.att.time_decay_w2: torch.Size([64, 768]) - torch.bfloat16\n",
      "blocks.7.att.time_value2_w1: torch.Size([768, 64]) - torch.bfloat16\n",
      "blocks.7.att.time_value2_w2: torch.Size([64, 768]) - torch.bfloat16\n",
      "blocks.7.att.time_faaaa: torch.Size([12, 64]) - torch.bfloat16\n",
      "blocks.7.att.receptance.weight: torch.Size([768, 768]) - torch.bfloat16\n",
      "blocks.7.att.key.weight: torch.Size([768, 768]) - torch.bfloat16\n",
      "blocks.7.att.value.weight: torch.Size([768, 768]) - torch.bfloat16\n",
      "blocks.7.att.output.weight: torch.Size([768, 768]) - torch.bfloat16\n",
      "blocks.7.att.ln_x.weight: torch.Size([768]) - torch.bfloat16\n",
      "blocks.7.att.ln_x.bias: torch.Size([768]) - torch.bfloat16\n",
      "blocks.7.ffn.time_maa_k: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.7.ffn.time_maa_r: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.7.ffn.key.weight: torch.Size([2688, 768]) - torch.bfloat16\n",
      "blocks.7.ffn.receptance.weight: torch.Size([768, 768]) - torch.bfloat16\n",
      "blocks.7.ffn.value.weight: torch.Size([768, 2688]) - torch.bfloat16\n",
      "blocks.8.ln1.weight: torch.Size([768]) - torch.bfloat16\n",
      "blocks.8.ln1.bias: torch.Size([768]) - torch.bfloat16\n",
      "blocks.8.ln2.weight: torch.Size([768]) - torch.bfloat16\n",
      "blocks.8.ln2.bias: torch.Size([768]) - torch.bfloat16\n",
      "blocks.8.att.time_maa_x: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.8.att.time_maa_q: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.8.att.time_maa_v_cache: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.8.att.time_maa_k: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.8.att.time_maa_v: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.8.att.time_maa_q_w1: torch.Size([768, 32]) - torch.bfloat16\n",
      "blocks.8.att.time_maa_q_w2: torch.Size([32, 768]) - torch.bfloat16\n",
      "blocks.8.att.time_maa_kv_w1: torch.Size([768, 64]) - torch.bfloat16\n",
      "blocks.8.att.time_maa_kv_w2: torch.Size([2, 32, 768]) - torch.bfloat16\n",
      "blocks.8.att.time_key_w1: torch.Size([768, 64]) - torch.bfloat16\n",
      "blocks.8.att.time_key_w2: torch.Size([64, 768]) - torch.bfloat16\n",
      "blocks.8.att.time_value_w1: torch.Size([768, 64]) - torch.bfloat16\n",
      "blocks.8.att.time_value_w2: torch.Size([64, 768]) - torch.bfloat16\n",
      "blocks.8.att.query.weight: torch.Size([768, 768]) - torch.bfloat16\n",
      "blocks.8.att.output.weight: torch.Size([768, 768]) - torch.bfloat16\n",
      "blocks.8.att.ln_q.weight: torch.Size([768]) - torch.bfloat16\n",
      "blocks.8.att.ln_q.bias: torch.Size([768]) - torch.bfloat16\n",
      "blocks.8.att.ln_k.weight: torch.Size([768]) - torch.bfloat16\n",
      "blocks.8.att.ln_k.bias: torch.Size([768]) - torch.bfloat16\n",
      "blocks.8.att.ln_v.weight: torch.Size([768]) - torch.bfloat16\n",
      "blocks.8.att.ln_v.bias: torch.Size([768]) - torch.bfloat16\n",
      "blocks.8.att.ln_x.weight: torch.Size([768]) - torch.bfloat16\n",
      "blocks.8.att.ln_x.bias: torch.Size([768]) - torch.bfloat16\n",
      "blocks.8.ffn.time_maa_k: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.8.ffn.time_maa_r: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.8.ffn.key.weight: torch.Size([2688, 768]) - torch.bfloat16\n",
      "blocks.8.ffn.receptance.weight: torch.Size([768, 768]) - torch.bfloat16\n",
      "blocks.8.ffn.value.weight: torch.Size([768, 2688]) - torch.bfloat16\n",
      "blocks.9.ln1.weight: torch.Size([768]) - torch.bfloat16\n",
      "blocks.9.ln1.bias: torch.Size([768]) - torch.bfloat16\n",
      "blocks.9.ln2.weight: torch.Size([768]) - torch.bfloat16\n",
      "blocks.9.ln2.bias: torch.Size([768]) - torch.bfloat16\n",
      "blocks.9.att.time_maa_x: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.9.att.time_maa_q: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.9.att.time_maa_v_cache: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.9.att.time_maa_k: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.9.att.time_maa_v: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.9.att.time_maa_q_w1: torch.Size([768, 32]) - torch.bfloat16\n",
      "blocks.9.att.time_maa_q_w2: torch.Size([32, 768]) - torch.bfloat16\n",
      "blocks.9.att.time_maa_kv_w1: torch.Size([768, 64]) - torch.bfloat16\n",
      "blocks.9.att.time_maa_kv_w2: torch.Size([2, 32, 768]) - torch.bfloat16\n",
      "blocks.9.att.time_key_w1: torch.Size([768, 64]) - torch.bfloat16\n",
      "blocks.9.att.time_key_w2: torch.Size([64, 768]) - torch.bfloat16\n",
      "blocks.9.att.time_value_w1: torch.Size([768, 64]) - torch.bfloat16\n",
      "blocks.9.att.time_value_w2: torch.Size([64, 768]) - torch.bfloat16\n",
      "blocks.9.att.query.weight: torch.Size([768, 768]) - torch.bfloat16\n",
      "blocks.9.att.output.weight: torch.Size([768, 768]) - torch.bfloat16\n",
      "blocks.9.att.ln_q.weight: torch.Size([768]) - torch.bfloat16\n",
      "blocks.9.att.ln_q.bias: torch.Size([768]) - torch.bfloat16\n",
      "blocks.9.att.ln_k.weight: torch.Size([768]) - torch.bfloat16\n",
      "blocks.9.att.ln_k.bias: torch.Size([768]) - torch.bfloat16\n",
      "blocks.9.att.ln_v.weight: torch.Size([768]) - torch.bfloat16\n",
      "blocks.9.att.ln_v.bias: torch.Size([768]) - torch.bfloat16\n",
      "blocks.9.att.ln_x.weight: torch.Size([768]) - torch.bfloat16\n",
      "blocks.9.att.ln_x.bias: torch.Size([768]) - torch.bfloat16\n",
      "blocks.9.ffn.time_maa_k: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.9.ffn.time_maa_r: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.9.ffn.key.weight: torch.Size([2688, 768]) - torch.bfloat16\n",
      "blocks.9.ffn.receptance.weight: torch.Size([768, 768]) - torch.bfloat16\n",
      "blocks.9.ffn.value.weight: torch.Size([768, 2688]) - torch.bfloat16\n",
      "blocks.10.ln1.weight: torch.Size([768]) - torch.bfloat16\n",
      "blocks.10.ln1.bias: torch.Size([768]) - torch.bfloat16\n",
      "blocks.10.ln2.weight: torch.Size([768]) - torch.bfloat16\n",
      "blocks.10.ln2.bias: torch.Size([768]) - torch.bfloat16\n",
      "blocks.10.att.time_maa_x: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.10.att.time_maa_q: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.10.att.time_maa_v_cache: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.10.att.time_maa_k: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.10.att.time_maa_v: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.10.att.time_maa_q_w1: torch.Size([768, 32]) - torch.bfloat16\n",
      "blocks.10.att.time_maa_q_w2: torch.Size([32, 768]) - torch.bfloat16\n",
      "blocks.10.att.time_maa_kv_w1: torch.Size([768, 64]) - torch.bfloat16\n",
      "blocks.10.att.time_maa_kv_w2: torch.Size([2, 32, 768]) - torch.bfloat16\n",
      "blocks.10.att.time_key_w1: torch.Size([768, 64]) - torch.bfloat16\n",
      "blocks.10.att.time_key_w2: torch.Size([64, 768]) - torch.bfloat16\n",
      "blocks.10.att.time_value_w1: torch.Size([768, 64]) - torch.bfloat16\n",
      "blocks.10.att.time_value_w2: torch.Size([64, 768]) - torch.bfloat16\n",
      "blocks.10.att.query.weight: torch.Size([768, 768]) - torch.bfloat16\n",
      "blocks.10.att.output.weight: torch.Size([768, 768]) - torch.bfloat16\n",
      "blocks.10.att.ln_q.weight: torch.Size([768]) - torch.bfloat16\n",
      "blocks.10.att.ln_q.bias: torch.Size([768]) - torch.bfloat16\n",
      "blocks.10.att.ln_k.weight: torch.Size([768]) - torch.bfloat16\n",
      "blocks.10.att.ln_k.bias: torch.Size([768]) - torch.bfloat16\n",
      "blocks.10.att.ln_v.weight: torch.Size([768]) - torch.bfloat16\n",
      "blocks.10.att.ln_v.bias: torch.Size([768]) - torch.bfloat16\n",
      "blocks.10.att.ln_x.weight: torch.Size([768]) - torch.bfloat16\n",
      "blocks.10.att.ln_x.bias: torch.Size([768]) - torch.bfloat16\n",
      "blocks.10.ffn.time_maa_k: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.10.ffn.time_maa_r: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.10.ffn.key.weight: torch.Size([2688, 768]) - torch.bfloat16\n",
      "blocks.10.ffn.receptance.weight: torch.Size([768, 768]) - torch.bfloat16\n",
      "blocks.10.ffn.value.weight: torch.Size([768, 2688]) - torch.bfloat16\n",
      "blocks.11.ln1.weight: torch.Size([768]) - torch.bfloat16\n",
      "blocks.11.ln1.bias: torch.Size([768]) - torch.bfloat16\n",
      "blocks.11.ln2.weight: torch.Size([768]) - torch.bfloat16\n",
      "blocks.11.ln2.bias: torch.Size([768]) - torch.bfloat16\n",
      "blocks.11.att.time_maa_x: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.11.att.time_maa_q: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.11.att.time_maa_v_cache: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.11.att.time_maa_k: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.11.att.time_maa_v: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.11.att.time_maa_q_w1: torch.Size([768, 32]) - torch.bfloat16\n",
      "blocks.11.att.time_maa_q_w2: torch.Size([32, 768]) - torch.bfloat16\n",
      "blocks.11.att.time_maa_kv_w1: torch.Size([768, 64]) - torch.bfloat16\n",
      "blocks.11.att.time_maa_kv_w2: torch.Size([2, 32, 768]) - torch.bfloat16\n",
      "blocks.11.att.time_key_w1: torch.Size([768, 64]) - torch.bfloat16\n",
      "blocks.11.att.time_key_w2: torch.Size([64, 768]) - torch.bfloat16\n",
      "blocks.11.att.time_value_w1: torch.Size([768, 64]) - torch.bfloat16\n",
      "blocks.11.att.time_value_w2: torch.Size([64, 768]) - torch.bfloat16\n",
      "blocks.11.att.query.weight: torch.Size([768, 768]) - torch.bfloat16\n",
      "blocks.11.att.output.weight: torch.Size([768, 768]) - torch.bfloat16\n",
      "blocks.11.att.ln_q.weight: torch.Size([768]) - torch.bfloat16\n",
      "blocks.11.att.ln_q.bias: torch.Size([768]) - torch.bfloat16\n",
      "blocks.11.att.ln_k.weight: torch.Size([768]) - torch.bfloat16\n",
      "blocks.11.att.ln_k.bias: torch.Size([768]) - torch.bfloat16\n",
      "blocks.11.att.ln_v.weight: torch.Size([768]) - torch.bfloat16\n",
      "blocks.11.att.ln_v.bias: torch.Size([768]) - torch.bfloat16\n",
      "blocks.11.att.ln_x.weight: torch.Size([768]) - torch.bfloat16\n",
      "blocks.11.att.ln_x.bias: torch.Size([768]) - torch.bfloat16\n",
      "blocks.11.ffn.time_maa_k: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.11.ffn.time_maa_r: torch.Size([1, 1, 768]) - torch.bfloat16\n",
      "blocks.11.ffn.key.weight: torch.Size([2688, 768]) - torch.bfloat16\n",
      "blocks.11.ffn.receptance.weight: torch.Size([768, 768]) - torch.bfloat16\n",
      "blocks.11.ffn.value.weight: torch.Size([768, 2688]) - torch.bfloat16\n",
      "ln_out.weight: torch.Size([768]) - torch.bfloat16\n",
      "ln_out.bias: torch.Size([768]) - torch.bfloat16\n",
      "head.weight: torch.Size([65536, 768]) - torch.bfloat16\n",
      "w_kv_cache_a.weight: torch.Size([48, 768]) - torch.bfloat16\n",
      "w_kv_cache_b.weight: torch.Size([768, 816]) - torch.bfloat16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspecting the v6 x060b2 trained models\n",
    "import os, torch\n",
    "\n",
    "goldfinch_x060b2 = torch.load('./.model/L12-D768-x060b2_goco-minipile.pth')\n",
    "\n",
    "def log_model_weights(model_weight):\n",
    "    # Lets get the hidden_size, and setup the test module\n",
    "    hidden_size = model_weight['emb.weight'].shape[1]\n",
    "    print(f\"### Model hidden_size: {hidden_size}\")\n",
    "\n",
    "    # List the model weights keys, and their shapes\n",
    "    print(f\"### model weights keys:\")\n",
    "    for key in model_weight:\n",
    "        print(f\"{key}: {model_weight[key].shape} - {model_weight[key].dtype}\")\n",
    "\n",
    "    # Return hidden_size\n",
    "    return hidden_size\n",
    "\n",
    "log_model_weights(goldfinch_x060b2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
